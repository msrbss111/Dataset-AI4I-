{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to understand how our dataset changes once we change it to a multi-label dataset by finding out the different\n",
    "# types of failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UDI</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>Machine failure</th>\n",
       "      <th>TWF</th>\n",
       "      <th>HDF</th>\n",
       "      <th>PWF</th>\n",
       "      <th>OSF</th>\n",
       "      <th>RNF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M14860</td>\n",
       "      <td>M</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1551</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>L47181</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>L47182</td>\n",
       "      <td>L</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.5</td>\n",
       "      <td>1498</td>\n",
       "      <td>49.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>L47183</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1433</td>\n",
       "      <td>39.5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>L47184</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UDI Product ID Type  Air temperature [K]  Process temperature [K]  \\\n",
       "0    1     M14860    M                298.1                    308.6   \n",
       "1    2     L47181    L                298.2                    308.7   \n",
       "2    3     L47182    L                298.1                    308.5   \n",
       "3    4     L47183    L                298.2                    308.6   \n",
       "4    5     L47184    L                298.2                    308.7   \n",
       "\n",
       "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Machine failure  TWF  \\\n",
       "0                    1551         42.8                0                0    0   \n",
       "1                    1408         46.3                3                0    0   \n",
       "2                    1498         49.4                5                0    0   \n",
       "3                    1433         39.5                7                0    0   \n",
       "4                    1408         40.0                9                0    0   \n",
       "\n",
       "   HDF  PWF  OSF  RNF  \n",
       "0    0    0    0    0  \n",
       "1    0    0    0    0  \n",
       "2    0    0    0    0  \n",
       "3    0    0    0    0  \n",
       "4    0    0    0    0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the csv and store it in a dataframe\n",
    "data = pd.read_csv('ai4i2020.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Machine failure\n",
       "0    9661\n",
       "1     339\n",
       "Name: UDI, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Machine failure counts\n",
    "data.groupby('Machine failure').count()['UDI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to find out what type of failures are there, because there is also a possibility for a \n",
    "# combination of two failures or more \n",
    "\n",
    "# So to get the different combinations we will change all the 1s to the name of the failure and 0s to an empty value \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'PWF', 'PWFOSF', 'TWF', 'OSF', 'RNF', 'HDF', 'TWFRNF',\n",
       "       'HDFPWF', 'HDFOSF', 'TWFOSF', 'TWFPWFOSF'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['TWF'] = data['TWF'].replace(1, \"TWF\") # This means that if column TWF is equal to 1 then the new column will be equal to 1\n",
    "data['TWF'] = data['TWF'].replace(0, \"\") # This means that if column TWF is equal to 0 then the new column value will depend on the other failure types\n",
    "data['HDF'] = data['HDF'].replace(1, \"HDF\")\n",
    "data['HDF'] = data['HDF'].replace(0, \"\")\n",
    "data[\"PWF\"] = data['PWF'].replace(1,\"PWF\")\n",
    "data[\"PWF\"] = data['PWF'].replace(0,\"\")\n",
    "data[\"OSF\"] = data['OSF'].replace(1,\"OSF\")\n",
    "data[\"OSF\"] = data['OSF'].replace(0,\"\")\n",
    "data[\"RNF\"] = data['RNF'].replace(1,\"RNF\")\n",
    "data[\"RNF\"] = data['RNF'].replace(0,\"\")\n",
    "\n",
    "data[\"error_class\"] = data[\"TWF\"] + data[\"HDF\"]+data[\"PWF\"]+data[\"OSF\"]+data[\"RNF\"]\n",
    "data[\"error_class\"].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the above results we see that there are 12 labels, and out of that 11 labels are machine failures \n",
    "# and 1 label is no machine failures.\n",
    "# So now lets check the frequency of each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "error_class\n",
       "             9652\n",
       "HDF           106\n",
       "HDFOSF          6\n",
       "HDFPWF          3\n",
       "OSF            78\n",
       "PWF            80\n",
       "PWFOSF         11\n",
       "RNF            18\n",
       "TWF            42\n",
       "TWFOSF          2\n",
       "TWFPWFOSF       1\n",
       "TWFRNF          1\n",
       "Name: UDI, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('error_class').count()['UDI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above results we see that the No machine failure should be equal to 9661 but we get 9652 which shows\n",
    "# there must be something more in the data \n",
    "\n",
    "# By going through the whole dataset based on the failures we see that when RNF failure occurs the machine does not\n",
    "# fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UDI</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>Machine failure</th>\n",
       "      <th>TWF</th>\n",
       "      <th>HDF</th>\n",
       "      <th>PWF</th>\n",
       "      <th>OSF</th>\n",
       "      <th>RNF</th>\n",
       "      <th>error_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>1222</td>\n",
       "      <td>M16081</td>\n",
       "      <td>M</td>\n",
       "      <td>297.0</td>\n",
       "      <td>308.3</td>\n",
       "      <td>1399</td>\n",
       "      <td>46.4</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>RNF</td>\n",
       "      <td>RNF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>1303</td>\n",
       "      <td>L48482</td>\n",
       "      <td>L</td>\n",
       "      <td>298.6</td>\n",
       "      <td>309.8</td>\n",
       "      <td>1505</td>\n",
       "      <td>45.7</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>RNF</td>\n",
       "      <td>RNF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>1749</td>\n",
       "      <td>H31162</td>\n",
       "      <td>H</td>\n",
       "      <td>298.4</td>\n",
       "      <td>307.7</td>\n",
       "      <td>1626</td>\n",
       "      <td>31.1</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>RNF</td>\n",
       "      <td>RNF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>2073</td>\n",
       "      <td>L49252</td>\n",
       "      <td>L</td>\n",
       "      <td>299.6</td>\n",
       "      <td>309.5</td>\n",
       "      <td>1570</td>\n",
       "      <td>35.5</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>RNF</td>\n",
       "      <td>RNF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>2560</td>\n",
       "      <td>L49739</td>\n",
       "      <td>L</td>\n",
       "      <td>299.3</td>\n",
       "      <td>309.0</td>\n",
       "      <td>1447</td>\n",
       "      <td>50.4</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>RNF</td>\n",
       "      <td>RNF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3065</th>\n",
       "      <td>3066</td>\n",
       "      <td>M17925</td>\n",
       "      <td>M</td>\n",
       "      <td>300.1</td>\n",
       "      <td>309.2</td>\n",
       "      <td>1687</td>\n",
       "      <td>27.7</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>RNF</td>\n",
       "      <td>RNF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3452</th>\n",
       "      <td>3453</td>\n",
       "      <td>H32866</td>\n",
       "      <td>H</td>\n",
       "      <td>301.6</td>\n",
       "      <td>310.5</td>\n",
       "      <td>1602</td>\n",
       "      <td>32.3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>RNF</td>\n",
       "      <td>RNF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5471</th>\n",
       "      <td>5472</td>\n",
       "      <td>L52651</td>\n",
       "      <td>L</td>\n",
       "      <td>302.7</td>\n",
       "      <td>312.3</td>\n",
       "      <td>1346</td>\n",
       "      <td>61.2</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>RNF</td>\n",
       "      <td>RNF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5489</th>\n",
       "      <td>5490</td>\n",
       "      <td>L52669</td>\n",
       "      <td>L</td>\n",
       "      <td>302.6</td>\n",
       "      <td>312.1</td>\n",
       "      <td>1499</td>\n",
       "      <td>35.0</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>RNF</td>\n",
       "      <td>RNF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5495</th>\n",
       "      <td>5496</td>\n",
       "      <td>H34909</td>\n",
       "      <td>H</td>\n",
       "      <td>302.9</td>\n",
       "      <td>312.5</td>\n",
       "      <td>1357</td>\n",
       "      <td>55.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>RNF</td>\n",
       "      <td>RNF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5509</th>\n",
       "      <td>5510</td>\n",
       "      <td>L52689</td>\n",
       "      <td>L</td>\n",
       "      <td>302.8</td>\n",
       "      <td>312.2</td>\n",
       "      <td>1509</td>\n",
       "      <td>36.5</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>RNF</td>\n",
       "      <td>RNF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5553</th>\n",
       "      <td>5554</td>\n",
       "      <td>L52733</td>\n",
       "      <td>L</td>\n",
       "      <td>302.5</td>\n",
       "      <td>311.9</td>\n",
       "      <td>1306</td>\n",
       "      <td>59.7</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>RNF</td>\n",
       "      <td>RNF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5639</th>\n",
       "      <td>5640</td>\n",
       "      <td>L52819</td>\n",
       "      <td>L</td>\n",
       "      <td>302.6</td>\n",
       "      <td>312.1</td>\n",
       "      <td>1668</td>\n",
       "      <td>28.7</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>RNF</td>\n",
       "      <td>RNF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6091</th>\n",
       "      <td>6092</td>\n",
       "      <td>L53271</td>\n",
       "      <td>L</td>\n",
       "      <td>300.9</td>\n",
       "      <td>310.7</td>\n",
       "      <td>1412</td>\n",
       "      <td>57.5</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>RNF</td>\n",
       "      <td>RNF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6913</th>\n",
       "      <td>6914</td>\n",
       "      <td>L54093</td>\n",
       "      <td>L</td>\n",
       "      <td>300.8</td>\n",
       "      <td>311.2</td>\n",
       "      <td>1481</td>\n",
       "      <td>38.5</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>RNF</td>\n",
       "      <td>RNF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6960</th>\n",
       "      <td>6961</td>\n",
       "      <td>L54140</td>\n",
       "      <td>L</td>\n",
       "      <td>300.7</td>\n",
       "      <td>311.0</td>\n",
       "      <td>1413</td>\n",
       "      <td>52.0</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>RNF</td>\n",
       "      <td>RNF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7488</th>\n",
       "      <td>7489</td>\n",
       "      <td>L54668</td>\n",
       "      <td>L</td>\n",
       "      <td>300.3</td>\n",
       "      <td>311.7</td>\n",
       "      <td>1545</td>\n",
       "      <td>43.5</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>RNF</td>\n",
       "      <td>RNF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7868</th>\n",
       "      <td>7869</td>\n",
       "      <td>H37282</td>\n",
       "      <td>H</td>\n",
       "      <td>300.4</td>\n",
       "      <td>311.9</td>\n",
       "      <td>1438</td>\n",
       "      <td>46.7</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>RNF</td>\n",
       "      <td>RNF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UDI Product ID Type  Air temperature [K]  Process temperature [K]  \\\n",
       "1221  1222     M16081    M                297.0                    308.3   \n",
       "1302  1303     L48482    L                298.6                    309.8   \n",
       "1748  1749     H31162    H                298.4                    307.7   \n",
       "2072  2073     L49252    L                299.6                    309.5   \n",
       "2559  2560     L49739    L                299.3                    309.0   \n",
       "3065  3066     M17925    M                300.1                    309.2   \n",
       "3452  3453     H32866    H                301.6                    310.5   \n",
       "5471  5472     L52651    L                302.7                    312.3   \n",
       "5489  5490     L52669    L                302.6                    312.1   \n",
       "5495  5496     H34909    H                302.9                    312.5   \n",
       "5509  5510     L52689    L                302.8                    312.2   \n",
       "5553  5554     L52733    L                302.5                    311.9   \n",
       "5639  5640     L52819    L                302.6                    312.1   \n",
       "6091  6092     L53271    L                300.9                    310.7   \n",
       "6913  6914     L54093    L                300.8                    311.2   \n",
       "6960  6961     L54140    L                300.7                    311.0   \n",
       "7488  7489     L54668    L                300.3                    311.7   \n",
       "7868  7869     H37282    H                300.4                    311.9   \n",
       "\n",
       "      Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Machine failure  \\\n",
       "1221                    1399         46.4              132                0   \n",
       "1302                    1505         45.7              144                0   \n",
       "1748                    1626         31.1              166                0   \n",
       "2072                    1570         35.5              189                0   \n",
       "2559                    1447         50.4              140                0   \n",
       "3065                    1687         27.7               95                0   \n",
       "3452                    1602         32.3                2                0   \n",
       "5471                    1346         61.2              170                0   \n",
       "5489                    1499         35.0              215                0   \n",
       "5495                    1357         55.0               12                0   \n",
       "5509                    1509         36.5               52                0   \n",
       "5553                    1306         59.7              172                0   \n",
       "5639                    1668         28.7              180                0   \n",
       "6091                    1412         57.5               16                0   \n",
       "6913                    1481         38.5              181                0   \n",
       "6960                    1413         52.0               91                0   \n",
       "7488                    1545         43.5              160                0   \n",
       "7868                    1438         46.7               41                0   \n",
       "\n",
       "     TWF HDF PWF OSF  RNF error_class  \n",
       "1221                  RNF         RNF  \n",
       "1302                  RNF         RNF  \n",
       "1748                  RNF         RNF  \n",
       "2072                  RNF         RNF  \n",
       "2559                  RNF         RNF  \n",
       "3065                  RNF         RNF  \n",
       "3452                  RNF         RNF  \n",
       "5471                  RNF         RNF  \n",
       "5489                  RNF         RNF  \n",
       "5495                  RNF         RNF  \n",
       "5509                  RNF         RNF  \n",
       "5553                  RNF         RNF  \n",
       "5639                  RNF         RNF  \n",
       "6091                  RNF         RNF  \n",
       "6913                  RNF         RNF  \n",
       "6960                  RNF         RNF  \n",
       "7488                  RNF         RNF  \n",
       "7868                  RNF         RNF  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If the data is not converted to string and if the binary values are used then the below commented code is\n",
    "# executed\n",
    "\n",
    "# data[(data['Machine failure'] == 0) & (data['RNF'] == '1')]\n",
    "\n",
    "data[(data['Machine failure'] == 0) & (data['RNF'] == 'RNF')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the above results we see that RNF failure does not cause any machine failure but may require fixing or\n",
    "# repairs which is beyond the scope of the project but RNF is a failure but not machine failure\n",
    "\n",
    "# But it still does not solve the issue of No machine errors being 9652 as shown above. So this could mean that there\n",
    "# could occur a machine failure without any of the failures occuring. In short, if all the known failures are 0, \n",
    "# the machine can still fail. Let's find out if this is true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UDI</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>Machine failure</th>\n",
       "      <th>TWF</th>\n",
       "      <th>HDF</th>\n",
       "      <th>PWF</th>\n",
       "      <th>OSF</th>\n",
       "      <th>RNF</th>\n",
       "      <th>error_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>1438</td>\n",
       "      <td>H30851</td>\n",
       "      <td>H</td>\n",
       "      <td>298.8</td>\n",
       "      <td>309.9</td>\n",
       "      <td>1439</td>\n",
       "      <td>45.2</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2749</th>\n",
       "      <td>2750</td>\n",
       "      <td>M17609</td>\n",
       "      <td>M</td>\n",
       "      <td>299.7</td>\n",
       "      <td>309.2</td>\n",
       "      <td>1685</td>\n",
       "      <td>28.9</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4044</th>\n",
       "      <td>4045</td>\n",
       "      <td>M18904</td>\n",
       "      <td>M</td>\n",
       "      <td>301.9</td>\n",
       "      <td>310.9</td>\n",
       "      <td>1419</td>\n",
       "      <td>47.7</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>4685</td>\n",
       "      <td>M19544</td>\n",
       "      <td>M</td>\n",
       "      <td>303.6</td>\n",
       "      <td>311.8</td>\n",
       "      <td>1421</td>\n",
       "      <td>44.8</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5536</th>\n",
       "      <td>5537</td>\n",
       "      <td>M20396</td>\n",
       "      <td>M</td>\n",
       "      <td>302.3</td>\n",
       "      <td>311.8</td>\n",
       "      <td>1363</td>\n",
       "      <td>54.0</td>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5941</th>\n",
       "      <td>5942</td>\n",
       "      <td>L53121</td>\n",
       "      <td>L</td>\n",
       "      <td>300.6</td>\n",
       "      <td>310.7</td>\n",
       "      <td>1438</td>\n",
       "      <td>48.5</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6478</th>\n",
       "      <td>6479</td>\n",
       "      <td>L53658</td>\n",
       "      <td>L</td>\n",
       "      <td>300.5</td>\n",
       "      <td>309.8</td>\n",
       "      <td>1663</td>\n",
       "      <td>29.1</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8506</th>\n",
       "      <td>8507</td>\n",
       "      <td>L55686</td>\n",
       "      <td>L</td>\n",
       "      <td>298.4</td>\n",
       "      <td>309.6</td>\n",
       "      <td>1710</td>\n",
       "      <td>27.3</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9015</th>\n",
       "      <td>9016</td>\n",
       "      <td>L56195</td>\n",
       "      <td>L</td>\n",
       "      <td>297.2</td>\n",
       "      <td>308.1</td>\n",
       "      <td>1431</td>\n",
       "      <td>49.7</td>\n",
       "      <td>210</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UDI Product ID Type  Air temperature [K]  Process temperature [K]  \\\n",
       "1437  1438     H30851    H                298.8                    309.9   \n",
       "2749  2750     M17609    M                299.7                    309.2   \n",
       "4044  4045     M18904    M                301.9                    310.9   \n",
       "4684  4685     M19544    M                303.6                    311.8   \n",
       "5536  5537     M20396    M                302.3                    311.8   \n",
       "5941  5942     L53121    L                300.6                    310.7   \n",
       "6478  6479     L53658    L                300.5                    309.8   \n",
       "8506  8507     L55686    L                298.4                    309.6   \n",
       "9015  9016     L56195    L                297.2                    308.1   \n",
       "\n",
       "      Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Machine failure  \\\n",
       "1437                    1439         45.2               40                1   \n",
       "2749                    1685         28.9              179                1   \n",
       "4044                    1419         47.7               20                1   \n",
       "4684                    1421         44.8              101                1   \n",
       "5536                    1363         54.0              119                1   \n",
       "5941                    1438         48.5               78                1   \n",
       "6478                    1663         29.1              145                1   \n",
       "8506                    1710         27.3              163                1   \n",
       "9015                    1431         49.7              210                1   \n",
       "\n",
       "     TWF HDF PWF OSF RNF error_class  \n",
       "1437                                  \n",
       "2749                                  \n",
       "4044                                  \n",
       "4684                                  \n",
       "5536                                  \n",
       "5941                                  \n",
       "6478                                  \n",
       "8506                                  \n",
       "9015                                  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If the data is not converted to string and if the binary values are used then the below commented code is\n",
    "# executed\n",
    "\n",
    "# data[(data['Machine failure'] == 1) & (data['PWF'] == 0) & (data['TWF'] == 0) & (data['RNF'] == 0) & \n",
    "#            (data['OSF'] == 0) & (data['HDF'] == 0)]\n",
    "\n",
    "data[(data['Machine failure'] == 1) & (data['PWF'] == \"\") & (data['TWF'] == \"\") & (data['RNF'] == \"\") &\n",
    "           (data['OSF'] == \"\") & (data['HDF'] == \"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So based on the above results we were right, there are instances where the machine failure occurs but none \n",
    "# of the other failures occur or are set to 1, so we need to distinguish it to another type. Hence bringing\n",
    "# the total types to 13 labels which are \n",
    "\n",
    "# 0 = No Error\n",
    "# 1 = TWFPWFOSF\n",
    "# 2 = TWFRNF\n",
    "# 3 = TWFOSF\n",
    "# 4 = PWFOSF\n",
    "# 5 = HDFPWF\n",
    "# 6 = HDFOSF\n",
    "# 7 = TWF\n",
    "# 8 = RNF - No machine failure but failure occurs\n",
    "# 9 = PWF\n",
    "# 10 = OSF\n",
    "# 11 = HDF\n",
    "# 12 = UD, Machine failure equal to 1 without any known failure occuring, so we categorize it as UnDefined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so now lets try to classify the multi-label dataset\n",
    "\n",
    "# We will be doing it differently since we ran into a few errors when using the above dataset since there were \n",
    "# NaN values that were difficult to remove and hence we had to make a few changes to the code as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unbalanced dataset of multi-labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes using Log Probabilities\n",
    "\n",
    "# using  additive smoothing so that probability will not be 0\n",
    "def Additive_smoothing(numerator, denominator, alpha, features):\n",
    "    return (numerator + alpha) / (denominator + (alpha * features))\n",
    "\n",
    "# applying log to the probabilities for easy computations\n",
    "def Log_probability(smoothing_probability):\n",
    "    return np.log(smoothing_probability)\n",
    "\n",
    "\n",
    "# The predictions is done by getting the probability for each class-feature using additive smoothing\n",
    "# and log transformation\n",
    "# query consits of the target values or y values\n",
    "def predict(query, number_of_features):\n",
    "   \n",
    "    # stores log probabilities of each class\n",
    "    log_class = {}\n",
    "    n_features = query.shape[0]\n",
    "    \n",
    "    # for each feature class we will calculate the log probabilities and sum them up to get \n",
    "    for target in class_list:\n",
    "        \n",
    "        logProbability = 0\n",
    "        \n",
    "        for col, feature in enumerate(query):\n",
    "            \n",
    "            # storing the name of current column\n",
    "            column = column_seq[col]\n",
    "            \n",
    "                \n",
    "            # For calculating log probability we will apply additive smoothing first P(A/B)\n",
    "            # P(A/B) = P(B/A) P(A) / P(B)\n",
    "            # P(A/B) = posterior (Log probability)\n",
    "            # P(B/A) = number_of_features[target][feature] likelihood\n",
    "            # P(B) = class_count[target], alpha, n_features, probbaility of B being true\n",
    "            logProbability += Log_probability(Additive_smoothing(number_of_features[target][feature],\\\n",
    "                                                                        class_count[target], alpha, n_features))\n",
    "        # We are calculating the prior here P(A)\n",
    "        #  adding log prior probability \n",
    "        # P(A) = class_count[target],\\ n_rows, alpha, n_features\n",
    "        logProbability += Log_probability(Additive_smoothing(class_count[target],\\\n",
    "                                                                    n_rows, alpha, n_features))\n",
    "        \n",
    "        log_class[target] = logProbability\n",
    "    return log_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UDI</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>Machine failure</th>\n",
       "      <th>TWF</th>\n",
       "      <th>HDF</th>\n",
       "      <th>PWF</th>\n",
       "      <th>OSF</th>\n",
       "      <th>RNF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M14860</td>\n",
       "      <td>M</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1551</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>L47181</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>L47182</td>\n",
       "      <td>L</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.5</td>\n",
       "      <td>1498</td>\n",
       "      <td>49.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>L47183</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1433</td>\n",
       "      <td>39.5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>L47184</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UDI Product ID Type  Air temperature [K]  Process temperature [K]  \\\n",
       "0    1     M14860    M                298.1                    308.6   \n",
       "1    2     L47181    L                298.2                    308.7   \n",
       "2    3     L47182    L                298.1                    308.5   \n",
       "3    4     L47183    L                298.2                    308.6   \n",
       "4    5     L47184    L                298.2                    308.7   \n",
       "\n",
       "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Machine failure  TWF  \\\n",
       "0                    1551         42.8                0                0    0   \n",
       "1                    1408         46.3                3                0    0   \n",
       "2                    1498         49.4                5                0    0   \n",
       "3                    1433         39.5                7                0    0   \n",
       "4                    1408         40.0                9                0    0   \n",
       "\n",
       "   HDF  PWF  OSF  RNF  \n",
       "0    0    0    0    0  \n",
       "1    0    0    0    0  \n",
       "2    0    0    0    0  \n",
       "3    0    0    0    0  \n",
       "4    0    0    0    0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the csv and store it in a dataframe\n",
    "import pandas as pd\n",
    "test_data = pd.read_csv('ai4i2020.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we set the machine failure to different unique values in order to distinguish them, by doing encoding instead\n",
    "# it would mix up the labels causing a confusion on what is what. \n",
    "\n",
    "# If we try to match the frequency after encoding we then fall into a problem since the frequency 1 is repeated twice\n",
    "# and so we won't be able to identify which is which.\n",
    "\n",
    "# Hence we use .where and set a unique value to each, then match and convert into an order from 0-12\n",
    "\n",
    "test_data['Machine failure'] += np.where((test_data['TWF'] == 1) & (test_data['PWF'] == 1)  & (test_data['OSF'] == 1), 1, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['TWF'] == 1) & (test_data['OSF'] == 1), 4, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['HDF'] == 1) & (test_data['OSF'] == 1), 8, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['HDF'] == 1) & (test_data['PWF'] == 1), 12, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['TWF'] == 1) & (test_data['RNF'] == 1), 16, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['PWF'] == 1) & (test_data['OSF'] == 1), 20, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['PWF'] == 1), 24, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['TWF'] == 1), 30, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['OSF'] == 1), 36, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['RNF'] == 1), 42, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['HDF'] == 1), 48, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['PWF'] == 0) & (test_data['TWF'] == 0) & (test_data['OSF'] == 0) &\n",
    "               (test_data['HDF'] == 0) & (test_data['Machine failure'] == 1), 52, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the unique labels are converted to a proper order \n",
    "\n",
    "test_data.loc[test_data['Machine failure'] == 116, \"Machine failure\"] = 1 # TWFPWFOSF\n",
    "test_data.loc[test_data['Machine failure'] == 89, \"Machine failure\"] = 2 # TWFRNF\n",
    "test_data.loc[test_data['Machine failure'] == 71, \"Machine failure\"] = 3 # TWFOSF\n",
    "test_data.loc[test_data['Machine failure'] == 81, \"Machine failure\"] = 4 # PWFOSF\n",
    "test_data.loc[test_data['Machine failure'] == 85, \"Machine failure\"] = 5 # HDFPWF\n",
    "test_data.loc[test_data['Machine failure'] == 93, \"Machine failure\"] = 6 # HDFOSF\n",
    "test_data.loc[test_data['Machine failure'] == 31, \"Machine failure\"] = 7 # TWF\n",
    "test_data.loc[test_data['Machine failure'] == 42, \"Machine failure\"] = 8 # RNF\n",
    "test_data.loc[test_data['Machine failure'] == 25, \"Machine failure\"] = 9 # PWF\n",
    "test_data.loc[test_data['Machine failure'] == 37, \"Machine failure\"] = 10 # OSF\n",
    "test_data.loc[test_data['Machine failure'] == 49, \"Machine failure\"] = 11 # HDF\n",
    "test_data.loc[test_data['Machine failure'] == 53, \"Machine failure\"] = 12 # UF\n",
    "\n",
    "\n",
    "# 0 - No machine failure\n",
    "# 1 = TWFPWFOSF\n",
    "# 2 = TWFRNF\n",
    "# 3 = TWFOSF\n",
    "# 4 = PWFOSF\n",
    "# 5 = HDFPWF\n",
    "# 6 = HDFOSF\n",
    "# 7 = TWF\n",
    "# 8 = RNF - No machine failure but failure occurs\n",
    "# 9 = PWF\n",
    "# 10 = OSF\n",
    "# 11 = HDF\n",
    "# 12 = UF, Machine failure is equal to 1 but none of the failure types had occured \n",
    "# which is basically an undefined failure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster sampling the dataset to 8000 where 6000 is used for training and 2000 is used for testing\n",
    "test_data = test_data.sample(frac=0.8, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UDI</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>TWF</th>\n",
       "      <th>HDF</th>\n",
       "      <th>PWF</th>\n",
       "      <th>OSF</th>\n",
       "      <th>RNF</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Machine failure</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7694</td>\n",
       "      <td>7694</td>\n",
       "      <td>7694</td>\n",
       "      <td>7694</td>\n",
       "      <td>7694</td>\n",
       "      <td>7694</td>\n",
       "      <td>7694</td>\n",
       "      <td>7694</td>\n",
       "      <td>7694</td>\n",
       "      <td>7694</td>\n",
       "      <td>7694</td>\n",
       "      <td>7694</td>\n",
       "      <td>7694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  UDI  Product ID  Type  Air temperature [K]  \\\n",
       "Machine failure                                                \n",
       "0                7694        7694  7694                 7694   \n",
       "2                   2           2     2                    2   \n",
       "3                   3           3     3                    3   \n",
       "4                   9           9     9                    9   \n",
       "5                   2           2     2                    2   \n",
       "6                   4           4     4                    4   \n",
       "7                  30          30    30                   30   \n",
       "8                  18          18    18                   18   \n",
       "9                  68          68    68                   68   \n",
       "10                 69          69    69                   69   \n",
       "11                 94          94    94                   94   \n",
       "12                  7           7     7                    7   \n",
       "\n",
       "                 Process temperature [K]  Rotational speed [rpm]  Torque [Nm]  \\\n",
       "Machine failure                                                                 \n",
       "0                                   7694                    7694         7694   \n",
       "2                                      2                       2            2   \n",
       "3                                      3                       3            3   \n",
       "4                                      9                       9            9   \n",
       "5                                      2                       2            2   \n",
       "6                                      4                       4            4   \n",
       "7                                     30                      30           30   \n",
       "8                                     18                      18           18   \n",
       "9                                     68                      68           68   \n",
       "10                                    69                      69           69   \n",
       "11                                    94                      94           94   \n",
       "12                                     7                       7            7   \n",
       "\n",
       "                 Tool wear [min]   TWF   HDF   PWF   OSF   RNF  \n",
       "Machine failure                                                 \n",
       "0                           7694  7694  7694  7694  7694  7694  \n",
       "2                              2     2     2     2     2     2  \n",
       "3                              3     3     3     3     3     3  \n",
       "4                              9     9     9     9     9     9  \n",
       "5                              2     2     2     2     2     2  \n",
       "6                              4     4     4     4     4     4  \n",
       "7                             30    30    30    30    30    30  \n",
       "8                             18    18    18    18    18    18  \n",
       "9                             68    68    68    68    68    68  \n",
       "10                            69    69    69    69    69    69  \n",
       "11                            94    94    94    94    94    94  \n",
       "12                             7     7     7     7     7     7  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We check to see whether any of the label is missing, since we did cluster sampling, there is a possibility that\n",
    "# the label with a low frequency would have been in the set of the remove data accounting to 0.2\n",
    "\n",
    "test_data.groupby('Machine failure').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove the failure columns since we have merged them with machine_failure\n",
    "test_data = test_data.drop(labels = ['TWF', 'HDF', 'PWF', 'OSF', 'RNF'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the column 'Type' with datatype object to int64 by encoding\n",
    "le =LabelEncoder()\n",
    "\n",
    "test_data['Type'] = le.fit_transform(test_data['Type'])\n",
    "test_data['Air temperature [K]'] = le.fit_transform(test_data['Air temperature [K]'])\n",
    "test_data['Process temperature [K]'] = le.fit_transform(test_data['Process temperature [K]'])\n",
    "test_data['Rotational speed [rpm]'] = le.fit_transform(test_data['Rotational speed [rpm]'])\n",
    "test_data['Torque [Nm]'] = le.fit_transform(test_data['Torque [Nm]'])\n",
    "test_data['Tool wear [min]'] = le.fit_transform(test_data['Tool wear [min]'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Defining X and y\n",
    "X = test_data.drop(labels = ['UDI', 'Product ID', 'Machine failure'], axis =1 )\n",
    "y = test_data['Machine failure']\n",
    "\n",
    "# X=test_data.iloc[:, 2:8]\n",
    "# y = test_data.iloc[:,8]\n",
    "\n",
    "\n",
    "# Splitting to training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 101)\n",
    "\n",
    "\n",
    "# defining terms to be used for calculation\n",
    "n_rows = X_train.shape[0] # Instances in X_train\n",
    "class_list = y_train.unique() # Number of labels\n",
    "column_seq = X_train.columns # Column names\n",
    "df = X_train.copy() # storing X_train (features) in a dataframe for calculating\n",
    "column_list = df.columns # List of column names in df\n",
    "\n",
    "# add target column\n",
    "df[\"target\"] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the probabilities\n",
    "\n",
    "feature_count = defaultdict(lambda: defaultdict(int)) # stores class- feature pair count\n",
    "class_count = defaultdict(int) # store frequency of class globally\n",
    "class_probability = defaultdict(int) # prior probability of class (class count / number of rows)\n",
    "alpha = 1\n",
    "\n",
    "if not df.empty:\n",
    "    \n",
    "    # for each row we will count the number of features\n",
    "    for row in df.values:\n",
    "        # storing the target class values\n",
    "        target_row = row[-1] \n",
    "        # going through each feature and add 1 to sum up to the number of features\n",
    "        for column in (row[:-1]):\n",
    "            feature_count[target_row][column] += 1 \n",
    "\n",
    "for target in y_train:\n",
    "    # storing the number of classes\n",
    "    target_class = len(class_count) \n",
    "    class_count[target] += 1\n",
    "\n",
    "# calculation class_count into probabilities\n",
    "for feature_class, count in class_count.items():\n",
    "    # converting counts to probabilities\n",
    "    class_probability[feature_class] = count / n_rows \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# hold predictions by our model\n",
    "y_pred = []\n",
    "\n",
    "data = X_test.copy()\n",
    "data['target'] = y_test\n",
    "\n",
    "# for each row in the dataset\n",
    "for row in data.values:\n",
    "    \n",
    "    # parse the target\n",
    "    target = row[-1]\n",
    "    \n",
    "    # query point\n",
    "    query = row[:-1]\n",
    "    \n",
    "    # get the log probability distribution\n",
    "    # pd = probability distribution\n",
    "    pd = predict(query, feature_count) #, class_feature_pair_mean, class_feature_pair_std)\n",
    "\n",
    "    # maximum a posteriori to get the class index\n",
    "    pred_class =np.argmax(list(pd.values()))\n",
    "\n",
    "    # get the class label\n",
    "    pred_label = list(feature_count.keys())[pred_class]\n",
    "    \n",
    "    # append the prediction to the list\n",
    "    y_pred.append(pred_label)\n",
    "\n",
    "y_pred = np.array(y_pred, dtype= int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Test labels:  [0 0 0 0 0 0 0 0 0 0]\n",
      "Predicted labels: [ 5 12  4  2  8  2  5  3  3  2]\n"
     ]
    }
   ],
   "source": [
    "# Printing out the test labels vs the predicted labels\n",
    "print(\"10 Test labels: \", y_test[:10].values)\n",
    "print(\"Predicted labels:\", y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the predicted labels we can match the label number to the below machine failure except \n",
    "# for No machine failure and RNF since the machine does not fail in these two cases\n",
    "\n",
    "# 0 - No machine failure\n",
    "# 1 = TWFPWFOSF\n",
    "# 2 = TWFRNF\n",
    "# 3 = TWFOSF\n",
    "# 4 = PWFOSF\n",
    "# 5 = HDFPWF\n",
    "# 6 = HDFOSF\n",
    "# 7 = TWF\n",
    "# 8 = RNF - No machine failure but failure occurs\n",
    "# 9 = PWF\n",
    "# 10 = OSF\n",
    "# 11 = HDF\n",
    "# 12 = UF, Machine failure is equal to 1 but none of the failure types had occured \n",
    "# which is basically an undefined failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.0155\n"
     ]
    }
   ],
   "source": [
    "# Printing accuracy\n",
    "# We notice that the accuracy is less and this is due to how the Naive bayes is created, since we are doing a \n",
    "# Probabilistic Naive Bayes we are getting a very low accuracy\n",
    "print(\"Test Accuracy: \",test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 14, 576, 585, 145, 194, 238,   5,  73,   0,   3,   0,  87],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   1,   1,   1,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   1,   2,   1,   0,   1,   2,   0,   0,   0,   0,   1],\n",
       "       [  0,   0,   0,   2,   0,   0,   0,   5,   0,   0,   0,   0],\n",
       "       [  0,   3,   3,   2,   3,   1,   0,   2,   4,   0,   0,   1],\n",
       "       [  0,   6,   0,   1,   0,   3,   0,   2,   0,   2,   0,   0],\n",
       "       [  0,   9,   1,   1,   4,   3,   0,   2,   0,   0,   2,   4],\n",
       "       [  0,   0,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.01      1920\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      1.00      0.00         1\n",
      "           4       0.01      0.33      0.01         3\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.29      0.25      0.27         8\n",
      "           8       0.06      0.71      0.11         7\n",
      "           9       1.00      0.21      0.35        19\n",
      "          10       0.40      0.14      0.21        14\n",
      "          11       1.00      0.08      0.14        26\n",
      "          12       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.02      2000\n",
      "   macro avg       0.31      0.23      0.09      2000\n",
      "weighted avg       0.99      0.02      0.02      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# printing the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold predictions by our model\n",
    "y_pred = []\n",
    "\n",
    "data = X_train.copy()\n",
    "data['target'] = y_train\n",
    "\n",
    "# for each row in the dataset\n",
    "for row in data.values:\n",
    "    \n",
    "    # parse the target\n",
    "    target = row[-1]\n",
    "    \n",
    "    # query point\n",
    "    query = row[:-1]\n",
    "    \n",
    "    # get the log probability distribution\n",
    "    # pd = probability distribution\n",
    "    pd = predict(query, feature_count) #, class_feature_pair_mean, class_feature_pair_std)\n",
    "\n",
    "    # maximum a posteriori to get the class index\n",
    "    pred_class =np.argmax(list(pd.values()))\n",
    "\n",
    "    # get the class label\n",
    "    pred_label = list(feature_count.keys())[pred_class]\n",
    "    \n",
    "    # append the prediction to the list\n",
    "    y_pred.append(pred_label)\n",
    "\n",
    "y_pred = np.array(y_pred, dtype= int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.023\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: \",accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unbalanced dataset binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file is read again so that any changes made will not affect the output this experimentation for this section\n",
    "# Also taking into consideration of the memory space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UDI</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>Machine failure</th>\n",
       "      <th>TWF</th>\n",
       "      <th>HDF</th>\n",
       "      <th>PWF</th>\n",
       "      <th>OSF</th>\n",
       "      <th>RNF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M14860</td>\n",
       "      <td>M</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1551</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>L47181</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>L47182</td>\n",
       "      <td>L</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.5</td>\n",
       "      <td>1498</td>\n",
       "      <td>49.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>L47183</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1433</td>\n",
       "      <td>39.5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>L47184</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UDI Product ID Type  Air temperature [K]  Process temperature [K]  \\\n",
       "0    1     M14860    M                298.1                    308.6   \n",
       "1    2     L47181    L                298.2                    308.7   \n",
       "2    3     L47182    L                298.1                    308.5   \n",
       "3    4     L47183    L                298.2                    308.6   \n",
       "4    5     L47184    L                298.2                    308.7   \n",
       "\n",
       "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Machine failure  TWF  \\\n",
       "0                    1551         42.8                0                0    0   \n",
       "1                    1408         46.3                3                0    0   \n",
       "2                    1498         49.4                5                0    0   \n",
       "3                    1433         39.5                7                0    0   \n",
       "4                    1408         40.0                9                0    0   \n",
       "\n",
       "   HDF  PWF  OSF  RNF  \n",
       "0    0    0    0    0  \n",
       "1    0    0    0    0  \n",
       "2    0    0    0    0  \n",
       "3    0    0    0    0  \n",
       "4    0    0    0    0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the csv and store it in a dataframe\n",
    "import pandas as pd\n",
    "test_data = pd.read_csv('ai4i2020.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we set the machine failure to different unique values in order to distinguish them, by doing encoding instead\n",
    "# it would mix up the labels causing a confusion on what is what. \n",
    "\n",
    "# If we try to match the frequency after encoding we then fall into a problem since the frequency 1 is repeated twice\n",
    "# and so we won't be able to identify which is which.\n",
    "\n",
    "# Hence we use .where and set a unique value to each, then match and convert into an order from 0-12\n",
    "\n",
    "test_data['Machine failure'] += np.where((test_data['TWF'] == 1) & (test_data['PWF'] == 1)  & (test_data['OSF'] == 1), 1, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['TWF'] == 1) & (test_data['OSF'] == 1), 4, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['HDF'] == 1) & (test_data['OSF'] == 1), 8, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['HDF'] == 1) & (test_data['PWF'] == 1), 12, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['TWF'] == 1) & (test_data['RNF'] == 1), 16, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['PWF'] == 1) & (test_data['OSF'] == 1), 20, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['PWF'] == 1), 24, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['TWF'] == 1), 30, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['OSF'] == 1), 36, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['RNF'] == 1), 42, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['HDF'] == 1), 48, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['PWF'] == 0) & (test_data['TWF'] == 0) & (test_data['OSF'] == 0) &\n",
    "               (test_data['HDF'] == 0) & (test_data['Machine failure'] == 1), 52, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the unique labels are converted to a proper order \n",
    "\n",
    "test_data.loc[test_data['Machine failure'] == 116, \"Machine failure\"] = 1 # TWFPWFOSF\n",
    "test_data.loc[test_data['Machine failure'] == 89, \"Machine failure\"] = 2 # TWFRNF\n",
    "test_data.loc[test_data['Machine failure'] == 71, \"Machine failure\"] = 3 # TWFOSF\n",
    "test_data.loc[test_data['Machine failure'] == 81, \"Machine failure\"] = 4 # PWFOSF\n",
    "test_data.loc[test_data['Machine failure'] == 85, \"Machine failure\"] = 5 # HDFPWF\n",
    "test_data.loc[test_data['Machine failure'] == 93, \"Machine failure\"] = 6 # HDFOSF\n",
    "test_data.loc[test_data['Machine failure'] == 31, \"Machine failure\"] = 7 # TWF\n",
    "test_data.loc[test_data['Machine failure'] == 42, \"Machine failure\"] = 8 # RNF\n",
    "test_data.loc[test_data['Machine failure'] == 25, \"Machine failure\"] = 9 # PWF\n",
    "test_data.loc[test_data['Machine failure'] == 37, \"Machine failure\"] = 10 # OSF\n",
    "test_data.loc[test_data['Machine failure'] == 49, \"Machine failure\"] = 11 # HDF\n",
    "test_data.loc[test_data['Machine failure'] == 53, \"Machine failure\"] = 12 # UF\n",
    "\n",
    "\n",
    "# 0 - No machine failure\n",
    "# 1 = TWFPWFOSF\n",
    "# 2 = TWFRNF\n",
    "# 3 = TWFOSF\n",
    "# 4 = PWFOSF\n",
    "# 5 = HDFPWF\n",
    "# 6 = HDFOSF\n",
    "# 7 = TWF\n",
    "# 8 = RNF - No machine failure but failure occurs\n",
    "# 9 = PWF\n",
    "# 10 = OSF\n",
    "# 11 = HDF\n",
    "# 12 = UF, Machine failure is equal to 1 but none of the failure types had occured \n",
    "# which is basically an undefined failure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster sampling the dataset to 8000 where 6000 is used for training and 2000 is used for testing\n",
    "test_data = test_data.sample(frac=0.8, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove the failure columns since we have merged them with machine_failure\n",
    "test_data = test_data.drop(labels = ['TWF', 'HDF', 'PWF', 'OSF', 'RNF'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Machine failure\n",
       "0     7700\n",
       "1        2\n",
       "2        1\n",
       "3        2\n",
       "4       10\n",
       "5        2\n",
       "6        1\n",
       "7       41\n",
       "8        7\n",
       "9       62\n",
       "10      70\n",
       "11      97\n",
       "12       5\n",
       "Name: UDI, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.groupby('Machine failure').count()['UDI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the column'Type' with datatype object to int64 by encoding\n",
    "le =LabelEncoder()\n",
    "test_data['Type'] = le.fit_transform(test_data['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295.3\n",
      "304.4\n"
     ]
    }
   ],
   "source": [
    "# Implementing binning\n",
    "# Taking the Minimum and maximum and diving it into three sections of low, medium and high\n",
    "min_value = test_data['Air temperature [K]'].min()\n",
    "max_value = test_data['Air temperature [K]'].max()\n",
    "print(min_value)\n",
    "print(max_value)\n",
    "\n",
    "# Store in Bins \n",
    "bins = np.linspace(min_value, max_value, 4)\n",
    "bins\n",
    "\n",
    "# Create labels\n",
    "labels = ['low', 'medium', 'high']\n",
    "\n",
    "# Replace to the value in the bin based on the label\n",
    "test_data['Air temperature [K]'] = pd.cut(test_data['Air temperature [K]'], bins=bins, labels=labels, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305.8\n",
      "313.8\n"
     ]
    }
   ],
   "source": [
    "# Implementing binning\n",
    "# Taking the Minimum and maximum and diving it into three sections of low, medium and high\n",
    "\n",
    "min_value_2 = test_data['Process temperature [K]'].min()\n",
    "max_value_2 = test_data['Process temperature [K]'].max()\n",
    "print(min_value_2)\n",
    "print(max_value_2)\n",
    "\n",
    "# Store in Bins \n",
    "bins_2 = np.linspace(min_value_2, max_value_2, 4)\n",
    "bins_2\n",
    "\n",
    "# Create labels\n",
    "labels_2 = ['low', 'medium', 'high']\n",
    "\n",
    "# Replace to the value in the bin based on the label\n",
    "test_data['Process temperature [K]'] = pd.cut(test_data['Process temperature [K]'], bins=bins_2, labels=labels_2, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168\n",
      "2886\n"
     ]
    }
   ],
   "source": [
    "# Implementing binning\n",
    "# Taking the Minimum and maximum and diving it into three sections of low, medium and high\n",
    "\n",
    "min_value_3 = test_data['Rotational speed [rpm]'].min()\n",
    "max_value_3 = test_data['Rotational speed [rpm]'].max()\n",
    "print(min_value_3)\n",
    "print(max_value_3)\n",
    "\n",
    "# Store in Bins \n",
    "bins_3 = np.linspace(min_value_3, max_value_3, 4)\n",
    "bins_3\n",
    "\n",
    "# Create labels\n",
    "labels_3 = ['low', 'medium', 'high']\n",
    "\n",
    "# Replace to the value in the bin based on the label\n",
    "test_data['Rotational speed [rpm]'] = pd.cut(test_data['Rotational speed [rpm]'], bins=bins_3, labels=labels_3, include_lowest=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8\n",
      "76.2\n"
     ]
    }
   ],
   "source": [
    "# Implementing binning\n",
    "# Taking the Minimum and maximum and diving it into three sections of low, medium and high\n",
    "\n",
    "min_value_4 = test_data['Torque [Nm]'].min()\n",
    "max_value_4 = test_data['Torque [Nm]'].max()\n",
    "print(min_value_4)\n",
    "print(max_value_4)\n",
    "\n",
    "# Store in Bins \n",
    "bins_4 = np.linspace(min_value_4, max_value_4, 4)\n",
    "bins_4\n",
    "\n",
    "# Create labels\n",
    "labels_4 = ['low', 'medium', 'high']\n",
    "\n",
    "# Replace to the value in the bin based on the label\n",
    "test_data['Torque [Nm]'] = pd.cut(test_data['Torque [Nm]'], bins=bins_4, labels=labels_4, include_lowest=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "253\n"
     ]
    }
   ],
   "source": [
    "# Implementing binning\n",
    "# Taking the Minimum and maximum and diving it into three sections of low, medium and high\n",
    "\n",
    "min_value_5 = test_data['Tool wear [min]'].min()\n",
    "max_value_5 = test_data['Tool wear [min]'].max()\n",
    "print(min_value_5)\n",
    "print(max_value_5)\n",
    "\n",
    "# Store in Bins \n",
    "bins_5 = np.linspace(min_value_5, max_value_5, 4)\n",
    "bins_5\n",
    "\n",
    "# Create labels\n",
    "labels_5 = ['low', 'medium', 'high']\n",
    "\n",
    "# Replace to the value in the bin based on the label\n",
    "test_data['Tool wear [min]'] = pd.cut(test_data['Tool wear [min]'], bins=bins_5, labels=labels_5, include_lowest=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the features for getting a better result\n",
    "\n",
    "le =LabelEncoder()\n",
    "\n",
    "test_data['Air temperature [K]'] = le.fit_transform(test_data['Air temperature [K]'])\n",
    "test_data['Process temperature [K]'] = le.fit_transform(test_data['Process temperature [K]'])\n",
    "test_data['Rotational speed [rpm]'] = le.fit_transform(test_data['Rotational speed [rpm]'])\n",
    "test_data['Torque [Nm]'] = le.fit_transform(test_data['Torque [Nm]'])\n",
    "test_data['Tool wear [min]'] = le.fit_transform(test_data['Tool wear [min]'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X and y\n",
    "X=test_data.iloc[:, 2:8]\n",
    "y = test_data.iloc[:,8]\n",
    "\n",
    "# Splitting to training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 101)\n",
    "\n",
    "\n",
    "\n",
    "# defining terms to be used for calculation\n",
    "n_rows = X_train.shape[0] # Instances in X_train\n",
    "class_list = y_train.unique() # Number of labels\n",
    "column_seq = X_train.columns # Column names\n",
    "df = X_train.copy() # storing X_train (features) in a dataframe for calculating\n",
    "column_list = df.columns # List of column names in df\n",
    "\n",
    "# add target column\n",
    "df[\"target\"] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the probabilities\n",
    "\n",
    "feature_count = defaultdict(lambda: defaultdict(int)) # stores class- feature pair count\n",
    "class_count = defaultdict(int) # store frequency of class globally\n",
    "class_probability = defaultdict(int) # prior probability of class (class count / number of rows)\n",
    "alpha = 1\n",
    "\n",
    "if not df.empty:\n",
    "    \n",
    "    # for each row we will count the number of features\n",
    "    for row in df.values:\n",
    "        # storing the target class values\n",
    "        target_row = row[-1] \n",
    "        # going through each feature and add 1 to sum up to the number of features\n",
    "        for column in (row[:-1]):\n",
    "            feature_count[target_row][column] += 1 \n",
    "\n",
    "for target in y_train:\n",
    "    # storing the number of classes\n",
    "    target_class = len(class_count) \n",
    "    class_count[target] += 1\n",
    "\n",
    "# calculation class_count into probabilities\n",
    "for feature_class, count in class_count.items():\n",
    "    # converting counts to probabilities\n",
    "    class_probability[feature_class] = count / n_rows \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will take some time since we have 120,000 instances\n",
    "\n",
    "# hold predictions by our model\n",
    "y_pred = []\n",
    "\n",
    "data = X_test.copy()\n",
    "data['target'] = y_test\n",
    "\n",
    "# for each row in the dataset\n",
    "for row in data.values:\n",
    "    \n",
    "    # parse the target\n",
    "    target = row[-1]\n",
    "    \n",
    "    # query point\n",
    "    query = row[:-1]\n",
    "    \n",
    "    # get the log probability distribution\n",
    "    # pd = probability distribution\n",
    "    pd = predict(query, feature_count) #, class_feature_pair_mean, class_feature_pair_std)\n",
    "\n",
    "    # maximum a posteriori to get the class index\n",
    "    pred_class =np.argmax(list(pd.values()))\n",
    "\n",
    "    # get the class label\n",
    "    pred_label = list(feature_count.keys())[pred_class]\n",
    "    \n",
    "    # append the prediction to the list\n",
    "    y_pred.append(pred_label)\n",
    "\n",
    "y_pred = np.array(y_pred, dtype= int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Test labels:  [0 0 0 0 0 0 0 0 0 0]\n",
      "Predicted labels: [0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Printing out the test labels vs the predicted labels\n",
    "print(\"10 Test labels: \", y_test[:10].values)\n",
    "print(\"Predicted labels:\", y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the predicted labels we can match the label number to the below machine failure except \n",
    "# for No machine failure and RNF since the machine does not fail in these two cases\n",
    "\n",
    "# 0 - No machine failure\n",
    "# 1 = TWFPWFOSF\n",
    "# 2 = TWFRNF\n",
    "# 3 = TWFOSF\n",
    "# 4 = PWFOSF\n",
    "# 5 = HDFPWF\n",
    "# 6 = HDFOSF\n",
    "# 7 = TWF\n",
    "# 8 = RNF - No machine failure but failure occurs\n",
    "# 9 = PWF\n",
    "# 10 = OSF\n",
    "# 11 = HDF\n",
    "# 12 = UF, Machine failure is equal to 1 but none of the failure types had occured \n",
    "# which is basically an undefined failure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.9655\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Printing accuracy\n",
    "print(\"Test Accuracy: \",test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1931,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   2,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   1,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   4,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   3,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   2,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [  13,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [  16,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [  26,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   2,    0,    0,    0,    0,    0,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1931\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         4\n",
      "           7       0.00      0.00      0.00         3\n",
      "           8       0.00      0.00      0.00         2\n",
      "           9       0.00      0.00      0.00        13\n",
      "          10       0.00      0.00      0.00        16\n",
      "          11       0.00      0.00      0.00        26\n",
      "          12       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.10      0.10      0.10      2000\n",
      "weighted avg       0.93      0.97      0.95      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# printing the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold predictions by our model\n",
    "y_pred = []\n",
    "\n",
    "data = X_train.copy()\n",
    "data['target'] = y_train\n",
    "\n",
    "# for each row in the dataset\n",
    "for row in data.values:\n",
    "    \n",
    "    # parse the target\n",
    "    target = row[-1]\n",
    "    \n",
    "    # query point\n",
    "    query = row[:-1]\n",
    "    \n",
    "    # get the log probability distribution\n",
    "    # pd = probability distribution\n",
    "    pd = predict(query, feature_count) #, class_feature_pair_mean, class_feature_pair_std)\n",
    "\n",
    "    # maximum a posteriori to get the class index\n",
    "    pred_class =np.argmax(list(pd.values()))\n",
    "\n",
    "    # get the class label\n",
    "    pred_label = list(feature_count.keys())[pred_class]\n",
    "    \n",
    "    # append the prediction to the list\n",
    "    y_pred.append(pred_label)\n",
    "\n",
    "y_pred = np.array(y_pred, dtype= int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9615\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: \",accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancing the dataset by undersampling\n",
    "# 1000 instances for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file is read again so that any changes made will not affect the output this experimentation for this section\n",
    "# Also taking into consideration of the memory space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UDI</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>Machine failure</th>\n",
       "      <th>TWF</th>\n",
       "      <th>HDF</th>\n",
       "      <th>PWF</th>\n",
       "      <th>OSF</th>\n",
       "      <th>RNF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M14860</td>\n",
       "      <td>M</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1551</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>L47181</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>L47182</td>\n",
       "      <td>L</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.5</td>\n",
       "      <td>1498</td>\n",
       "      <td>49.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>L47183</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1433</td>\n",
       "      <td>39.5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>L47184</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UDI Product ID Type  Air temperature [K]  Process temperature [K]  \\\n",
       "0    1     M14860    M                298.1                    308.6   \n",
       "1    2     L47181    L                298.2                    308.7   \n",
       "2    3     L47182    L                298.1                    308.5   \n",
       "3    4     L47183    L                298.2                    308.6   \n",
       "4    5     L47184    L                298.2                    308.7   \n",
       "\n",
       "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Machine failure  TWF  \\\n",
       "0                    1551         42.8                0                0    0   \n",
       "1                    1408         46.3                3                0    0   \n",
       "2                    1498         49.4                5                0    0   \n",
       "3                    1433         39.5                7                0    0   \n",
       "4                    1408         40.0                9                0    0   \n",
       "\n",
       "   HDF  PWF  OSF  RNF  \n",
       "0    0    0    0    0  \n",
       "1    0    0    0    0  \n",
       "2    0    0    0    0  \n",
       "3    0    0    0    0  \n",
       "4    0    0    0    0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Reading the csv and store it in a dataframe\n",
    "data = pd.read_csv('ai4i2020.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we set the machine failure to different unique values in order to distinguish them, by doing encoding instead\n",
    "# it would mix up the labels causing a confusion on what is what. \n",
    "\n",
    "# If we try to match the frequency after encoding we then fall into a problem since the frequency 1 is repeated twice\n",
    "# and so we won't be able to identify which is which.\n",
    "\n",
    "# Hence we use .where and set a unique value to each, then match and convert into an order from 0-12\n",
    "\n",
    "test_data = data.copy()\n",
    "\n",
    "                                         \n",
    "test_data['Machine failure'] += np.where((test_data['TWF'] == 1) & (test_data['PWF'] == 1)  & (test_data['OSF'] == 1), 1, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['TWF'] == 1) & (test_data['OSF'] == 1), 4, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['HDF'] == 1) & (test_data['OSF'] == 1), 8, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['HDF'] == 1) & (test_data['PWF'] == 1), 12, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['TWF'] == 1) & (test_data['RNF'] == 1), 16, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['PWF'] == 1) & (test_data['OSF'] == 1), 20, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['PWF'] == 1), 24, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['TWF'] == 1), 30, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['OSF'] == 1), 36, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['RNF'] == 1), 42, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['HDF'] == 1), 48, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['PWF'] == 0) & (test_data['TWF'] == 0) & (test_data['OSF'] == 0) &\n",
    "               (test_data['HDF'] == 0) & (test_data['Machine failure'] == 1), 52, 0)\n",
    "\n",
    "\n",
    "# Here the unique labels are converted to a proper order \n",
    "\n",
    "test_data.loc[test_data['Machine failure'] == 116, \"Machine failure\"] = 1 # TWFPWFOSF\n",
    "test_data.loc[test_data['Machine failure'] == 89, \"Machine failure\"] = 2 # TWFRNF\n",
    "test_data.loc[test_data['Machine failure'] == 71, \"Machine failure\"] = 3 # TWFOSF\n",
    "test_data.loc[test_data['Machine failure'] == 81, \"Machine failure\"] = 4 # PWFOSF\n",
    "test_data.loc[test_data['Machine failure'] == 85, \"Machine failure\"] = 5 # HDFPWF\n",
    "test_data.loc[test_data['Machine failure'] == 93, \"Machine failure\"] = 6 # HDFOSF\n",
    "test_data.loc[test_data['Machine failure'] == 31, \"Machine failure\"] = 7 # TWF\n",
    "test_data.loc[test_data['Machine failure'] == 42, \"Machine failure\"] = 8 # RNF\n",
    "test_data.loc[test_data['Machine failure'] == 25, \"Machine failure\"] = 9 # PWF\n",
    "test_data.loc[test_data['Machine failure'] == 37, \"Machine failure\"] = 10 # OSF\n",
    "test_data.loc[test_data['Machine failure'] == 49, \"Machine failure\"] = 11 # HDF\n",
    "test_data.loc[test_data['Machine failure'] == 53, \"Machine failure\"] = 12 # UF\n",
    "\n",
    "\n",
    "# 0 - No machine failure\n",
    "# 1 = TWFPWFOSF\n",
    "# 2 = TWFRNF\n",
    "# 3 = TWFOSF\n",
    "# 4 = PWFOSF\n",
    "# 5 = HDFPWF\n",
    "# 6 = HDFOSF\n",
    "# 7 = TWF\n",
    "# 8 = RNF - No machine failure but failure occurs\n",
    "# 9 = PWF\n",
    "# 10 = OSF\n",
    "# 11 = HDF\n",
    "# 12 = UF, Machine failure is equal to 1 but none of the failure types had occured \n",
    "# which is basically an undefined failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove the failure columns since we have merged them with machine_failure\n",
    "test_data = test_data.drop(labels = ['TWF', 'HDF', 'PWF', 'OSF', 'RNF'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling the dataset to 1000 for each label\n",
    "sample = 1000\n",
    "test_data = test_data.groupby('Machine failure').apply(lambda x: x.sample(sample,replace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we had use group by machine failure, the index is now machine failure so in X_train we will be able to\n",
    "# see the target label (Machine failure) so for that we need to change the index from group by machine failure\n",
    "# to the normal count index\n",
    "test_data = test_data.droplevel(0).reset_index()\n",
    "test_data = test_data.drop(labels = 'index', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13000"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster sampling the dataset to 8060 where 6045 is used for training and 2015 is used for testing\n",
    "test_data = test_data.sample(frac=0.62, replace=True) # 8060 instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the column'Type' with datatype object to int64 by encoding\n",
    "\n",
    "le =LabelEncoder()\n",
    "test_data['Type'] = le.fit_transform(test_data['Type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X and y\n",
    "X=test_data.iloc[:, 2:8]\n",
    "y = test_data.iloc[:,8]\n",
    "\n",
    "\n",
    "# Splitting to training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = True, stratify = y)\n",
    "\n",
    "\n",
    "# defining terms to be used for calculation\n",
    "n_rows = X_train.shape[0] # Instances in X_train\n",
    "class_list = y_train.unique() # Number of labels\n",
    "column_seq = X_train.columns # Column names\n",
    "df = X_train.copy() # storing X_train (features) in a dataframe for calculating\n",
    "column_list = df.columns # List of column names in df\n",
    "\n",
    "# add target column\n",
    "df[\"target\"] = y_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the probabilities\n",
    "feature_count = defaultdict(lambda: defaultdict(int)) # stores class- feature pair count\n",
    "class_count = defaultdict(int) # store frequency of class globally\n",
    "class_probability = defaultdict(int) # prior probability of class (class count / number of rows)\n",
    "alpha = 1\n",
    "\n",
    "if not df.empty:\n",
    "    \n",
    "    # for each row we will count the number of features\n",
    "    for row in df.values:\n",
    "        # storing the target class values\n",
    "        target_row = row[-1] \n",
    "        # going through each feature and add 1 to sum up to the number of features\n",
    "        for column in (row[:-1]):\n",
    "            feature_count[target_row][column] += 1 \n",
    "\n",
    "for target in y_train:\n",
    "    # storing the number of classes\n",
    "    target_class = len(class_count) \n",
    "    class_count[target] += 1\n",
    "\n",
    "# calculation class_count into probabilities\n",
    "for feature_class, count in class_count.items():\n",
    "    # converting counts to probabilities\n",
    "    class_probability[feature_class] = count / n_rows \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold predictions by our model\n",
    "y_pred = []\n",
    "\n",
    "data = X_test.copy()\n",
    "data['target'] = y_test\n",
    "\n",
    "# for each row in the dataset\n",
    "for row in data.values:\n",
    "    \n",
    "    # parse the target\n",
    "    target = row[-1]\n",
    "    \n",
    "    # query point\n",
    "    query = row[:-1]\n",
    "    \n",
    "    # get the log probability distribution\n",
    "    # pd = probability distribution\n",
    "    pd = predict(query, feature_count) #, class_feature_pair_mean, class_feature_pair_std)\n",
    "\n",
    "    # maximum a posteriori to get the class index\n",
    "    pred_class =np.argmax(list(pd.values()))\n",
    "\n",
    "    # get the class label\n",
    "    pred_label = list(feature_count.keys())[pred_class]\n",
    "    \n",
    "    # append the prediction to the list\n",
    "    y_pred.append(pred_label)\n",
    "\n",
    "y_pred = np.array(y_pred, dtype= int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Test labels:  [ 1 11 10  6  8  4  8  5 10 12]\n",
      "Predicted labels: [ 1 11 10  6  8  4  8  5 10 12]\n"
     ]
    }
   ],
   "source": [
    "# Printing out the test labels vs the predicted labels\n",
    "print(\"10 Test labels: \", y_test[:10].values)\n",
    "print(\"Predicted labels:\", y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the predicted labels we can match the label number to the below machine failure except \n",
    "# for No machine failure and RNF since the machine does not fail in these two cases\n",
    "\n",
    "# 0 - No machine failure\n",
    "# 1 = TWFPWFOSF\n",
    "# 2 = TWFRNF\n",
    "# 3 = TWFOSF\n",
    "# 4 = PWFOSF\n",
    "# 5 = HDFPWF\n",
    "# 6 = HDFOSF\n",
    "# 7 = TWF\n",
    "# 8 = RNF - No machine failure but failure occurs\n",
    "# 9 = PWF\n",
    "# 10 = OSF\n",
    "# 11 = HDF\n",
    "# 12 = UF, Machine failure is equal to 1 but none of the failure types had occured \n",
    "# which is basically an undefined failure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.9687344913151364\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Printing accuracy\n",
    "# We notice that the accuracy is less and this is due to how the Naive bayes is created, since we are doing a \n",
    "# Probabilistic Naive Bayes we are getting a very low accuracy\n",
    "print(\"Test Accuracy: \",test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 93,   0,   2,   4,   2,   0,   0,   9,   4,   8,   7,  12,   5],\n",
       "       [  0, 152,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0, 150,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0, 163,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0, 155,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0, 150,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 171,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 147,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 157,   0,   0,   0,   0],\n",
       "       [  1,   0,   0,   0,   0,   0,   0,   0,   1, 158,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 156,   0,   0],\n",
       "       [  1,   0,   0,   0,   0,   3,   2,   0,   0,   1,   0, 148,   1],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 152]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.64      0.77       146\n",
      "           1       1.00      1.00      1.00       152\n",
      "           2       0.99      1.00      0.99       150\n",
      "           3       0.98      1.00      0.99       163\n",
      "           4       0.99      1.00      0.99       155\n",
      "           5       0.98      1.00      0.99       150\n",
      "           6       0.99      1.00      0.99       171\n",
      "           7       0.94      1.00      0.97       147\n",
      "           8       0.97      1.00      0.98       157\n",
      "           9       0.95      0.99      0.97       160\n",
      "          10       0.96      1.00      0.98       156\n",
      "          11       0.93      0.95      0.94       156\n",
      "          12       0.96      1.00      0.98       152\n",
      "\n",
      "    accuracy                           0.97      2015\n",
      "   macro avg       0.97      0.97      0.97      2015\n",
      "weighted avg       0.97      0.97      0.97      2015\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold predictions by our model\n",
    "y_pred = []\n",
    "\n",
    "data = X_train.copy()\n",
    "data['target'] = y_train\n",
    "\n",
    "# for each row in the dataset\n",
    "for row in data.values:\n",
    "    \n",
    "    # parse the target\n",
    "    target = row[-1]\n",
    "    \n",
    "    # query point\n",
    "    query = row[:-1]\n",
    "    \n",
    "    # get the log probability distribution\n",
    "    # pd = probability distribution\n",
    "    pd = predict(query, feature_count) #, class_feature_pair_mean, class_feature_pair_std)\n",
    "\n",
    "    # maximum a posteriori to get the class index\n",
    "    pred_class =np.argmax(list(pd.values()))\n",
    "\n",
    "    # get the class label\n",
    "    pred_label = list(feature_count.keys())[pred_class]\n",
    "    \n",
    "    # append the prediction to the list\n",
    "    y_pred.append(pred_label)\n",
    "\n",
    "y_pred = np.array(y_pred, dtype= int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9831265508684863\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: \",accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Under-sampled Balanced dataset using binning\n",
    "# 1000 instances for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UDI</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>Machine failure</th>\n",
       "      <th>TWF</th>\n",
       "      <th>HDF</th>\n",
       "      <th>PWF</th>\n",
       "      <th>OSF</th>\n",
       "      <th>RNF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M14860</td>\n",
       "      <td>M</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1551</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>L47181</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>L47182</td>\n",
       "      <td>L</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.5</td>\n",
       "      <td>1498</td>\n",
       "      <td>49.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>L47183</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1433</td>\n",
       "      <td>39.5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>L47184</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UDI Product ID Type  Air temperature [K]  Process temperature [K]  \\\n",
       "0    1     M14860    M                298.1                    308.6   \n",
       "1    2     L47181    L                298.2                    308.7   \n",
       "2    3     L47182    L                298.1                    308.5   \n",
       "3    4     L47183    L                298.2                    308.6   \n",
       "4    5     L47184    L                298.2                    308.7   \n",
       "\n",
       "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Machine failure  TWF  \\\n",
       "0                    1551         42.8                0                0    0   \n",
       "1                    1408         46.3                3                0    0   \n",
       "2                    1498         49.4                5                0    0   \n",
       "3                    1433         39.5                7                0    0   \n",
       "4                    1408         40.0                9                0    0   \n",
       "\n",
       "   HDF  PWF  OSF  RNF  \n",
       "0    0    0    0    0  \n",
       "1    0    0    0    0  \n",
       "2    0    0    0    0  \n",
       "3    0    0    0    0  \n",
       "4    0    0    0    0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Reading the csv and store it in a dataframe\n",
    "data = pd.read_csv('ai4i2020.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we set the machine failure to different unique values in order to distinguish them, by doing encoding instead\n",
    "# it would mix up the labels causing a confusion on what is what. \n",
    "\n",
    "# If we try to match the frequency after encoding we then fall into a problem since the frequency 1 is repeated twice\n",
    "# and so we won't be able to identify which is which.\n",
    "\n",
    "# Hence we use .where and set a unique value to each, then match and convert into an order from 0-12\n",
    "\n",
    "\n",
    "test_data = data.copy()\n",
    "\n",
    "test_data['Machine failure'] += np.where((test_data['TWF'] == 1) & (test_data['PWF'] == 1)  & (test_data['OSF'] == 1), 1, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['TWF'] == 1) & (test_data['OSF'] == 1), 4, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['HDF'] == 1) & (test_data['OSF'] == 1), 8, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['HDF'] == 1) & (test_data['PWF'] == 1), 12, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['TWF'] == 1) & (test_data['RNF'] == 1), 16, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['PWF'] == 1) & (test_data['OSF'] == 1), 20, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['PWF'] == 1), 24, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['TWF'] == 1), 30, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['OSF'] == 1), 36, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['RNF'] == 1), 42, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['HDF'] == 1), 48, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['PWF'] == 0) & (test_data['TWF'] == 0) & (test_data['OSF'] == 0) &\n",
    "               (test_data['HDF'] == 0) & (test_data['Machine failure'] == 1), 52, 0)\n",
    "\n",
    "\n",
    "\n",
    "# Here the unique labels are converted to a proper order \n",
    "\n",
    "test_data.loc[test_data['Machine failure'] == 116, \"Machine failure\"] = 1 # TWFPWFOSF\n",
    "test_data.loc[test_data['Machine failure'] == 89, \"Machine failure\"] = 2 # TWFRNF\n",
    "test_data.loc[test_data['Machine failure'] == 71, \"Machine failure\"] = 3 # TWFOSF\n",
    "test_data.loc[test_data['Machine failure'] == 81, \"Machine failure\"] = 4 # PWFOSF\n",
    "test_data.loc[test_data['Machine failure'] == 85, \"Machine failure\"] = 5 # HDFPWF\n",
    "test_data.loc[test_data['Machine failure'] == 93, \"Machine failure\"] = 6 # HDFOSF\n",
    "test_data.loc[test_data['Machine failure'] == 31, \"Machine failure\"] = 7 # TWF\n",
    "test_data.loc[test_data['Machine failure'] == 42, \"Machine failure\"] = 8 # RNF\n",
    "test_data.loc[test_data['Machine failure'] == 25, \"Machine failure\"] = 9 # PWF\n",
    "test_data.loc[test_data['Machine failure'] == 37, \"Machine failure\"] = 10 # OSF\n",
    "test_data.loc[test_data['Machine failure'] == 49, \"Machine failure\"] = 11 # HDF\n",
    "test_data.loc[test_data['Machine failure'] == 53, \"Machine failure\"] = 12 # UF\n",
    "\n",
    "\n",
    "# 0 - No machine failure\n",
    "# 1 = TWFPWFOSF\n",
    "# 2 = TWFRNF\n",
    "# 3 = TWFOSF\n",
    "# 4 = PWFOSF\n",
    "# 5 = HDFPWF\n",
    "# 6 = HDFOSF\n",
    "# 7 = TWF\n",
    "# 8 = RNF - No machine failure but failure occurs\n",
    "# 9 = PWF\n",
    "# 10 = OSF\n",
    "# 11 = HDF\n",
    "# 12 = UF, Machine failure is equal to 1 but none of the failure types had occured \n",
    "# which is basically an undefined failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove the failure columns since we have merged them with machine_failure\n",
    "test_data = test_data.drop(labels = ['TWF', 'HDF', 'PWF', 'OSF', 'RNF'], axis = 1)\n",
    "\n",
    "# Undersampling the dataset to 1000 for each label\n",
    "sample = 1000\n",
    "test_data = test_data.groupby('Machine failure').apply(lambda x: x.sample(sample,replace=True))\n",
    "\n",
    "\n",
    "# Since we had use group by machine failure, the index is now machine failure so in X_train we will be able to\n",
    "# see the target label (Machine failure) so for that we need to change the index from group by machine failure\n",
    "# to the normal count index\n",
    "test_data = test_data.droplevel(0).reset_index()\n",
    "test_data = test_data.drop(labels = 'index', axis =1)\n",
    "\n",
    "\n",
    "# Setting the column'Type' with datatype object to int64 by encoding\n",
    "le =LabelEncoder()\n",
    "test_data['Type'] = le.fit_transform(test_data['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295.3\n",
      "304.4\n"
     ]
    }
   ],
   "source": [
    "# Implementing binning\n",
    "# Taking the Minimum and maximum and diving it into three sections of low, medium and high\n",
    "\n",
    "min_value = test_data['Air temperature [K]'].min()\n",
    "max_value = test_data['Air temperature [K]'].max()\n",
    "print(min_value)\n",
    "print(max_value)\n",
    "\n",
    "# Store in Bins \n",
    "bins = np.linspace(min_value, max_value, 4)\n",
    "bins\n",
    "\n",
    "# Create labels\n",
    "labels = ['low', 'medium', 'high']\n",
    "\n",
    "# Replace to the value in the bin based on the label\n",
    "test_data['Air temperature [K]'] = pd.cut(test_data['Air temperature [K]'], bins=bins, labels=labels, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305.7\n",
      "313.7\n"
     ]
    }
   ],
   "source": [
    "# Implementing binning\n",
    "# Taking the Minimum and maximum and diving it into three sections of low, medium and high\n",
    "\n",
    "min_value_2 = test_data['Process temperature [K]'].min()\n",
    "max_value_2 = test_data['Process temperature [K]'].max()\n",
    "print(min_value_2)\n",
    "print(max_value_2)\n",
    "\n",
    "# Store in Bins \n",
    "bins_2 = np.linspace(min_value_2, max_value_2, 4)\n",
    "bins_2\n",
    "\n",
    "# Create labels\n",
    "labels_2 = ['low', 'medium', 'high']\n",
    "\n",
    "# Replace to the value in the bin based on the label\n",
    "test_data['Process temperature [K]'] = pd.cut(test_data['Process temperature [K]'], bins=bins_2, labels=labels_2, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1181\n",
      "2886\n"
     ]
    }
   ],
   "source": [
    "# Implementing binning\n",
    "# Taking the Minimum and maximum and diving it into three sections of low, medium and high\n",
    "\n",
    "min_value_3 = test_data['Rotational speed [rpm]'].min()\n",
    "max_value_3 = test_data['Rotational speed [rpm]'].max()\n",
    "print(min_value_3)\n",
    "print(max_value_3)\n",
    "\n",
    "# Store in Bins \n",
    "bins_3 = np.linspace(min_value_3, max_value_3, 4)\n",
    "bins_3\n",
    "\n",
    "# Create labels\n",
    "labels_3 = ['low', 'medium', 'high']\n",
    "\n",
    "# Replace to the value in the bin based on the label\n",
    "test_data['Rotational speed [rpm]'] = pd.cut(test_data['Rotational speed [rpm]'], bins=bins_3, labels=labels_3, include_lowest=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8\n",
      "76.6\n"
     ]
    }
   ],
   "source": [
    "# Implementing binning\n",
    "# Taking the Minimum and maximum and diving it into three sections of low, medium and high\n",
    "\n",
    "min_value_4 = test_data['Torque [Nm]'].min()\n",
    "max_value_4 = test_data['Torque [Nm]'].max()\n",
    "print(min_value_4)\n",
    "print(max_value_4)\n",
    "\n",
    "# Store in Bins \n",
    "bins_4 = np.linspace(min_value_4, max_value_4, 4)\n",
    "bins_4\n",
    "\n",
    "# Create labels\n",
    "labels_4 = ['low', 'medium', 'high']\n",
    "\n",
    "# Replace to the value in the bin based on the label\n",
    "test_data['Torque [Nm]'] = pd.cut(test_data['Torque [Nm]'], bins=bins_4, labels=labels_4, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "253\n"
     ]
    }
   ],
   "source": [
    "# Implementing binning\n",
    "# Taking the Minimum and maximum and diving it into three sections of low, medium and high\n",
    "\n",
    "min_value_5 = test_data['Tool wear [min]'].min()\n",
    "max_value_5 = test_data['Tool wear [min]'].max()\n",
    "print(min_value_5)\n",
    "print(max_value_5)\n",
    "\n",
    "# Store in Bins \n",
    "bins_5 = np.linspace(min_value_5, max_value_5, 4)\n",
    "bins_5\n",
    "\n",
    "# Create labels\n",
    "labels_5 = ['low', 'medium', 'high']\n",
    "\n",
    "# Replace to the value in the bin based on the label\n",
    "test_data['Tool wear [min]'] = pd.cut(test_data['Tool wear [min]'], bins=bins_5, labels=labels_5, include_lowest=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the features for getting a better result\n",
    "\n",
    "le =LabelEncoder()\n",
    "\n",
    "test_data['Type'] = le.fit_transform(test_data['Type'])\n",
    "test_data['Air temperature [K]'] = le.fit_transform(test_data['Air temperature [K]'])\n",
    "test_data['Process temperature [K]'] = le.fit_transform(test_data['Process temperature [K]'])\n",
    "test_data['Rotational speed [rpm]'] = le.fit_transform(test_data['Rotational speed [rpm]'])\n",
    "test_data['Torque [Nm]'] = le.fit_transform(test_data['Torque [Nm]'])\n",
    "test_data['Tool wear [min]'] = le.fit_transform(test_data['Tool wear [min]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster sampling the dataset to 8060 where 6045 is used for training and 2015 is used for testing\n",
    "test_data = test_data.sample(frac=0.62, replace=True) # 8060 instances\n",
    "\n",
    "# Defining X and y\n",
    "X = test_data.iloc[:, 2:8]\n",
    "y = test_data.iloc[:,8]\n",
    "\n",
    "\n",
    "# Splitting to training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = True)\n",
    "\n",
    "\n",
    "# defining terms to be used for calculation\n",
    "n_rows = X_train.shape[0] # Instances in X_train\n",
    "class_list = y_train.unique() # Number of labels\n",
    "column_seq = X_train.columns # Column names\n",
    "df = X_train.copy() # storing X_train (features) in a dataframe for calculating\n",
    "column_list = df.columns # List of column names in df\n",
    "\n",
    "# add target column\n",
    "df[\"target\"] = y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the probabilities\n",
    "feature_count = defaultdict(lambda: defaultdict(int)) # stores class- feature pair count\n",
    "class_count = defaultdict(int) # store frequency of class globally\n",
    "class_probability = defaultdict(int) # prior probability of class (class count / number of rows)\n",
    "alpha = 1\n",
    "\n",
    "if not df.empty:\n",
    "    \n",
    "    # for each row we will count the number of features\n",
    "    for row in df.values:\n",
    "        # storing the target class values\n",
    "        target_row = row[-1] \n",
    "        # going through each feature and add 1 to sum up to the number of features\n",
    "        for column in (row[:-1]):\n",
    "            feature_count[target_row][column] += 1 \n",
    "\n",
    "for target in y_train:\n",
    "    # storing the number of classes\n",
    "    target_class = len(class_count) \n",
    "    class_count[target] += 1\n",
    "\n",
    "# calculation class_count into probabilities\n",
    "for feature_class, count in class_count.items():\n",
    "    # converting counts to probabilities\n",
    "    class_probability[feature_class] = count / n_rows \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold predictions by our model\n",
    "y_pred = []\n",
    "\n",
    "data = X_test.copy()\n",
    "data['target'] = y_test\n",
    "\n",
    "# for each row in the dataset\n",
    "for row in data.values:\n",
    "    \n",
    "    # parse the target\n",
    "    target = row[-1]\n",
    "    \n",
    "    # query point\n",
    "    query = row[:-1]\n",
    "    \n",
    "    # get the log probability distribution\n",
    "    # pd = probability distribution\n",
    "    pd = predict(query, feature_count) #, class_feature_pair_mean, class_feature_pair_std)\n",
    "\n",
    "    # maximum a posteriori to get the class index\n",
    "    pred_class =np.argmax(list(pd.values()))\n",
    "\n",
    "    # get the class label\n",
    "    pred_label = list(feature_count.keys())[pred_class]\n",
    "    \n",
    "    # append the prediction to the list\n",
    "    y_pred.append(pred_label)\n",
    "\n",
    "y_pred = np.array(y_pred, dtype= int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Test labels:  [ 8  5  4 11 10  3  4  3  0 11]\n",
      "Predicted labels: [11  7  7 12  1 11  6  3 12 12]\n"
     ]
    }
   ],
   "source": [
    "# Printing out the test labels vs the predicted labels\n",
    "print(\"10 Test labels: \", y_test[:10].values)\n",
    "print(\"Predicted labels:\", y_pred[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the predicted labels we can match the label number to the below machine failure except \n",
    "# for No machine failure and RNF since the machine does not fail in these two cases\n",
    "\n",
    "# 0 - No machine failure\n",
    "# 1 = TWFPWFOSF\n",
    "# 2 = TWFRNF\n",
    "# 3 = TWFOSF\n",
    "# 4 = PWFOSF\n",
    "# 5 = HDFPWF\n",
    "# 6 = HDFOSF\n",
    "# 7 = TWF\n",
    "# 8 = RNF - No machine failure but failure occurs\n",
    "# 9 = PWF\n",
    "# 10 = OSF\n",
    "# 11 = HDF\n",
    "# 12 = UF, Machine failure is equal to 1 but none of the failure types had occured \n",
    "# which is basically an undefined failure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.26004962779156326\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Printing accuracy\n",
    "# We notice that the accuracy is less and this is due to how the Naive bayes is created, since we are doing a \n",
    "# Probabilistic Naive Bayes we are getting a very low accuracy\n",
    "print(\"Test Accuracy: \",test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 83,   5,   0,   0,   3,   0,   1,   6,   0,   4,   9,  14,  24],\n",
       "       [  0, 142,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 160,   0],\n",
       "       [  0,   0,   0,  76,   0,   0,   0,   0,   0,   0,   0,  70,   0],\n",
       "       [  0,   0,   0,  24,  12,   0,  29,  16,   0,   0,  54,  43,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  44,   0,   0,  48,  45,   0],\n",
       "       [  0,   0,   0,   0,  91,   0,  90,   0,   0,   0,   0,   0,   0],\n",
       "       [ 12,   6,   0,   1,  17,   0,   0,  28,   0,  13,  10,  17,  41],\n",
       "       [ 45,   0,   0,   0,  19,   0,  26,   0,   0,   0,  12,  35,  29],\n",
       "       [ 30,   5,   0,   0,  17,   0,   8,  10,   0,  17,  14,  21,  27],\n",
       "       [  4,   6,   0,   1,  31,   0,  41,   0,   0,   1,   7,  66,  15],\n",
       "       [ 13,   8,   0,   7,  20,   0,  18,  10,   0,   0,  19,  24,  33],\n",
       "       [ 55,  12,   0,   0,   0,   0,   0,   8,   0,  18,   0,   0,  45]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.56      0.42       149\n",
      "           1       0.77      1.00      0.87       142\n",
      "           2       0.00      0.00      0.00       160\n",
      "           3       0.70      0.52      0.60       146\n",
      "           4       0.06      0.07      0.06       178\n",
      "           5       0.00      0.00      0.00       137\n",
      "           6       0.42      0.50      0.46       181\n",
      "           7       0.23      0.19      0.21       145\n",
      "           8       0.00      0.00      0.00       166\n",
      "           9       0.32      0.11      0.17       149\n",
      "          10       0.04      0.04      0.04       172\n",
      "          11       0.05      0.16      0.07       152\n",
      "          12       0.21      0.33      0.26       138\n",
      "\n",
      "    accuracy                           0.26      2015\n",
      "   macro avg       0.24      0.27      0.24      2015\n",
      "weighted avg       0.24      0.26      0.24      2015\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# printing the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# hold predictions by our model\n",
    "y_pred = []\n",
    "\n",
    "data = X_train.copy()\n",
    "data['target'] = y_train\n",
    "\n",
    "# for each row in the dataset\n",
    "for row in data.values:\n",
    "    \n",
    "    # parse the target\n",
    "    target = row[-1]\n",
    "    \n",
    "    # query point\n",
    "    query = row[:-1]\n",
    "    \n",
    "    # get the log probability distribution\n",
    "    # pd = probability distribution\n",
    "    pd = predict(query, feature_count) #, class_feature_pair_mean, class_feature_pair_std)\n",
    "\n",
    "    # maximum a posteriori to get the class index\n",
    "    pred_class =np.argmax(list(pd.values()))\n",
    "\n",
    "    # get the class label\n",
    "    pred_label = list(feature_count.keys())[pred_class]\n",
    "    \n",
    "    # append the prediction to the list\n",
    "    y_pred.append(pred_label)\n",
    "\n",
    "y_pred = np.array(y_pred, dtype= int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.27758478081058724\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: \",accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UDI</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>Machine failure</th>\n",
       "      <th>TWF</th>\n",
       "      <th>HDF</th>\n",
       "      <th>PWF</th>\n",
       "      <th>OSF</th>\n",
       "      <th>RNF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M14860</td>\n",
       "      <td>M</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1551</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>L47181</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>L47182</td>\n",
       "      <td>L</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.5</td>\n",
       "      <td>1498</td>\n",
       "      <td>49.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>L47183</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1433</td>\n",
       "      <td>39.5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>L47184</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UDI Product ID Type  Air temperature [K]  Process temperature [K]  \\\n",
       "0    1     M14860    M                298.1                    308.6   \n",
       "1    2     L47181    L                298.2                    308.7   \n",
       "2    3     L47182    L                298.1                    308.5   \n",
       "3    4     L47183    L                298.2                    308.6   \n",
       "4    5     L47184    L                298.2                    308.7   \n",
       "\n",
       "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Machine failure  TWF  \\\n",
       "0                    1551         42.8                0                0    0   \n",
       "1                    1408         46.3                3                0    0   \n",
       "2                    1498         49.4                5                0    0   \n",
       "3                    1433         39.5                7                0    0   \n",
       "4                    1408         40.0                9                0    0   \n",
       "\n",
       "   HDF  PWF  OSF  RNF  \n",
       "0    0    0    0    0  \n",
       "1    0    0    0    0  \n",
       "2    0    0    0    0  \n",
       "3    0    0    0    0  \n",
       "4    0    0    0    0  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Oversampling dataset\n",
    "# 10000 instances for each label\n",
    "import pandas as pd\n",
    "# Reading the csv and store it in a dataframe\n",
    "data = pd.read_csv('ai4i2020.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we set the machine failure to different unique values in order to distinguish them, by doing encoding instead\n",
    "# it would mix up the labels causing a confusion on what is what. \n",
    "\n",
    "# If we try to match the frequency after encoding we then fall into a problem since the frequency 1 is repeated twice\n",
    "# and so we won't be able to identify which is which.\n",
    "\n",
    "# Hence we use .where and set a unique value to each, then match and convert into an order from 0-12\n",
    "\n",
    "test_data = data.copy()\n",
    "\n",
    "test_data['Machine failure'] += np.where((test_data['TWF'] == 1) & (test_data['PWF'] == 1)  & (test_data['OSF'] == 1), 1, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['TWF'] == 1) & (test_data['OSF'] == 1), 4, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['HDF'] == 1) & (test_data['OSF'] == 1), 8, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['HDF'] == 1) & (test_data['PWF'] == 1), 12, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['TWF'] == 1) & (test_data['RNF'] == 1), 16, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['PWF'] == 1) & (test_data['OSF'] == 1), 20, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['PWF'] == 1), 24, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['TWF'] == 1), 30, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['OSF'] == 1), 36, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['RNF'] == 1), 42, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['HDF'] == 1), 48, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['PWF'] == 0) & (test_data['TWF'] == 0) & (test_data['OSF'] == 0) &\n",
    "               (test_data['HDF'] == 0) & (test_data['Machine failure'] == 1), 52, 0)\n",
    "\n",
    "\n",
    "# Here the unique labels are converted to a proper order \n",
    "\n",
    "test_data.loc[test_data['Machine failure'] == 116, \"Machine failure\"] = 1 # TWFPWFOSF\n",
    "test_data.loc[test_data['Machine failure'] == 89, \"Machine failure\"] = 2 # TWFRNF\n",
    "test_data.loc[test_data['Machine failure'] == 71, \"Machine failure\"] = 3 # TWFOSF\n",
    "test_data.loc[test_data['Machine failure'] == 81, \"Machine failure\"] = 4 # PWFOSF\n",
    "test_data.loc[test_data['Machine failure'] == 85, \"Machine failure\"] = 5 # HDFPWF\n",
    "test_data.loc[test_data['Machine failure'] == 93, \"Machine failure\"] = 6 # HDFOSF\n",
    "test_data.loc[test_data['Machine failure'] == 31, \"Machine failure\"] = 7 # TWF\n",
    "test_data.loc[test_data['Machine failure'] == 42, \"Machine failure\"] = 8 # RNF\n",
    "test_data.loc[test_data['Machine failure'] == 25, \"Machine failure\"] = 9 # PWF\n",
    "test_data.loc[test_data['Machine failure'] == 37, \"Machine failure\"] = 10 # OSF\n",
    "test_data.loc[test_data['Machine failure'] == 49, \"Machine failure\"] = 11 # HDF\n",
    "test_data.loc[test_data['Machine failure'] == 53, \"Machine failure\"] = 12 # UF\n",
    "\n",
    "\n",
    "# 0 - No machine failure\n",
    "# 1 = TWFPWFOSF\n",
    "# 2 = TWFRNF\n",
    "# 3 = TWFOSF\n",
    "# 4 = PWFOSF\n",
    "# 5 = HDFPWF\n",
    "# 6 = HDFOSF\n",
    "# 7 = TWF\n",
    "# 8 = RNF - No machine failure but failure occurs\n",
    "# 9 = PWF\n",
    "# 10 = OSF\n",
    "# 11 = HDF\n",
    "# 12 = UF, Machine failure is equal to 1 but none of the failure types had occured \n",
    "# which is basically an undefined failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove the failure columns since we have merged them with machine_failure\n",
    "test_data = test_data.drop(labels = ['TWF', 'HDF', 'PWF', 'OSF', 'RNF'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Oversampling the dataset to 10000 for each label\n",
    "sample = 10000\n",
    "test_data = test_data.groupby('Machine failure').apply(lambda x: x.sample(sample,replace=True))\n",
    "\n",
    "\n",
    "# Since we had use group by machine failure, the index is now machine failure so in X_train we will be able to\n",
    "# see the target label (Machine failure) so for that we need to change the index from group by machine failure\n",
    "# to the normal count index\n",
    "test_data = test_data.droplevel(0).reset_index()\n",
    "test_data = test_data.drop(labels = 'index', axis =1)\n",
    "\n",
    "\n",
    "# Setting the column'Type' with datatype object to int64 by encoding\n",
    "le =LabelEncoder()\n",
    "test_data['Type'] = le.fit_transform(test_data['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster sampling the dataset from 130000 to 13000 instances\n",
    "test_data = test_data.sample(frac=0.1, replace=True) # 13000 instances\n",
    "\n",
    "\n",
    "# Cluster sampling the dataset from 13000 to 8060 where 6045 is used for training and 2015 is used for testing\n",
    "test_data = test_data.sample(frac=0.62, replace=True) # 8060 instances\n",
    "\n",
    "\n",
    "\n",
    "# Defining X and y\n",
    "X = test_data.drop(labels = ['UDI', 'Product ID', 'Machine failure'], axis =1 )\n",
    "y = test_data['Machine failure']\n",
    "\n",
    "\n",
    "# Splitting to training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 101, stratify = y)\n",
    "\n",
    "\n",
    "\n",
    "# defining terms to be used for calculation\n",
    "n_rows = X_train.shape[0] # Instances in X_train\n",
    "class_list = y_train.unique() # Number of labels\n",
    "column_seq = X_train.columns # Column names\n",
    "df = X_train.copy() # storing X_train (features) in a dataframe for calculating\n",
    "column_list = df.columns # List of column names in df\n",
    "\n",
    "# add target column\n",
    "df[\"target\"] = y_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the probabilities\n",
    "feature_count = defaultdict(lambda: defaultdict(int)) # stores class- feature pair count\n",
    "class_count = defaultdict(int) # store frequency of class globally\n",
    "class_probability = defaultdict(int) # prior probability of class (class count / number of rows)\n",
    "alpha = 1\n",
    "\n",
    "if not df.empty:\n",
    "    \n",
    "    # for each row we will count the number of features\n",
    "    for row in df.values:\n",
    "        # storing the target class values\n",
    "        target_row = row[-1] \n",
    "        # going through each feature and add 1 to sum up to the number of features\n",
    "        for column in (row[:-1]):\n",
    "            feature_count[target_row][column] += 1 \n",
    "\n",
    "for target in y_train:\n",
    "    # storing the number of classes\n",
    "    target_class = len(class_count) \n",
    "    class_count[target] += 1\n",
    "\n",
    "# calculation class_count into probabilities\n",
    "for feature_class, count in class_count.items():\n",
    "    # converting counts to probabilities\n",
    "    class_probability[feature_class] = count / n_rows \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will take some time since we have 120,000 instances\n",
    "\n",
    "# hold predictions by our model\n",
    "y_pred = []\n",
    "\n",
    "data = X_test.copy()\n",
    "data['target'] = y_test\n",
    "\n",
    "# for each row in the dataset\n",
    "for row in data.values:\n",
    "    \n",
    "    # parse the target\n",
    "    target = row[-1]\n",
    "    \n",
    "    # query point\n",
    "    query = row[:-1]\n",
    "    \n",
    "    # get the log probability distribution\n",
    "    # pd = probability distribution\n",
    "    pd = predict(query, feature_count) #, class_feature_pair_mean, class_feature_pair_std)\n",
    "\n",
    "    # maximum a posteriori to get the class index\n",
    "    pred_class =np.argmax(list(pd.values()))\n",
    "\n",
    "    # get the class label\n",
    "    pred_label = list(feature_count.keys())[pred_class]\n",
    "    \n",
    "    # append the prediction to the list\n",
    "    y_pred.append(pred_label)\n",
    "\n",
    "y_pred = np.array(y_pred, dtype= int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Test labels:  [10  5  2  9  8  3  7  9 11 10]\n",
      "Predicted labels: [10  5  2  9  8  3  7  9 11 10]\n"
     ]
    }
   ],
   "source": [
    "# Printing out the test labels vs the predicted labels\n",
    "print(\"10 Test labels: \", y_test[:10].values)\n",
    "print(\"Predicted labels:\", y_pred[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the predicted labels we can match the label number to the below machine failure except \n",
    "# for No machine failure and RNF since the machine does not fail in these two cases\n",
    "\n",
    "# 0 - No machine failure\n",
    "# 1 = TWFPWFOSF\n",
    "# 2 = TWFRNF\n",
    "# 3 = TWFOSF\n",
    "# 4 = PWFOSF\n",
    "# 5 = HDFPWF\n",
    "# 6 = HDFOSF\n",
    "# 7 = TWF\n",
    "# 8 = RNF - No machine failure but failure occurs\n",
    "# 9 = PWF\n",
    "# 10 = OSF\n",
    "# 11 = HDF\n",
    "# 12 = UF, Machine failure is equal to 1 but none of the failure types had occured \n",
    "# which is basically an undefined failure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.9652605459057072\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Printing accuracy\n",
    "# We notice that the accuracy is less and this is due to how the Naive bayes is created, since we are doing a \n",
    "# Probabilistic Naive Bayes we are getting a very low accuracy\n",
    "print(\"Test Accuracy: \",test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 95,   0,   1,   1,   4,   2,   0,   6,   6,   8,   9,  11,   1],\n",
       "       [  0, 162,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0, 163,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0, 154,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0, 149,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0, 170,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 152,   0,   0,   0,   0,   0,   0],\n",
       "       [  6,   0,   0,   0,   0,   0,   0, 151,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 149,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   1,   3, 148,   1,   1,   4],\n",
       "       [  0,   0,   0,   0,   0,   3,   0,   0,   0,   0, 145,   1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0, 159,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 148]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.66      0.78       144\n",
      "           1       1.00      1.00      1.00       162\n",
      "           2       0.99      1.00      1.00       163\n",
      "           3       0.99      1.00      1.00       154\n",
      "           4       0.97      1.00      0.99       149\n",
      "           5       0.97      1.00      0.99       170\n",
      "           6       0.99      1.00      1.00       152\n",
      "           7       0.96      0.96      0.96       157\n",
      "           8       0.94      1.00      0.97       149\n",
      "           9       0.95      0.94      0.94       158\n",
      "          10       0.94      0.97      0.95       149\n",
      "          11       0.92      0.99      0.96       160\n",
      "          12       0.97      1.00      0.98       148\n",
      "\n",
      "    accuracy                           0.97      2015\n",
      "   macro avg       0.96      0.96      0.96      2015\n",
      "weighted avg       0.97      0.97      0.96      2015\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing the classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hold predictions by our model\n",
    "y_pred = []\n",
    "\n",
    "data = X_train.copy()\n",
    "data['target'] = y_train\n",
    "\n",
    "# for each row in the dataset\n",
    "for row in data.values:\n",
    "    \n",
    "    # parse the target\n",
    "    target = row[-1]\n",
    "    \n",
    "    # query point\n",
    "    query = row[:-1]\n",
    "    \n",
    "    # get the log probability distribution\n",
    "    # pd = probability distribution\n",
    "    pd = predict(query, feature_count) #, class_feature_pair_mean, class_feature_pair_std)\n",
    "\n",
    "    # maximum a posteriori to get the class index\n",
    "    pred_class =np.argmax(list(pd.values()))\n",
    "\n",
    "    # get the class label\n",
    "    pred_label = list(feature_count.keys())[pred_class]\n",
    "    \n",
    "    # append the prediction to the list\n",
    "    y_pred.append(pred_label)\n",
    "\n",
    "y_pred = np.array(y_pred, dtype= int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.9839536807278743\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: \",accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UDI</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>Machine failure</th>\n",
       "      <th>TWF</th>\n",
       "      <th>HDF</th>\n",
       "      <th>PWF</th>\n",
       "      <th>OSF</th>\n",
       "      <th>RNF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M14860</td>\n",
       "      <td>M</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1551</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>L47181</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>L47182</td>\n",
       "      <td>L</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.5</td>\n",
       "      <td>1498</td>\n",
       "      <td>49.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>L47183</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1433</td>\n",
       "      <td>39.5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>L47184</td>\n",
       "      <td>L</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UDI Product ID Type  Air temperature [K]  Process temperature [K]  \\\n",
       "0    1     M14860    M                298.1                    308.6   \n",
       "1    2     L47181    L                298.2                    308.7   \n",
       "2    3     L47182    L                298.1                    308.5   \n",
       "3    4     L47183    L                298.2                    308.6   \n",
       "4    5     L47184    L                298.2                    308.7   \n",
       "\n",
       "   Rotational speed [rpm]  Torque [Nm]  Tool wear [min]  Machine failure  TWF  \\\n",
       "0                    1551         42.8                0                0    0   \n",
       "1                    1408         46.3                3                0    0   \n",
       "2                    1498         49.4                5                0    0   \n",
       "3                    1433         39.5                7                0    0   \n",
       "4                    1408         40.0                9                0    0   \n",
       "\n",
       "   HDF  PWF  OSF  RNF  \n",
       "0    0    0    0    0  \n",
       "1    0    0    0    0  \n",
       "2    0    0    0    0  \n",
       "3    0    0    0    0  \n",
       "4    0    0    0    0  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Over sampling with binning\n",
    "import pandas as pd\n",
    "# Reading the csv and store it in a dataframe\n",
    "data = pd.read_csv('ai4i2020.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we set the machine failure to different unique values in order to distinguish them, by doing encoding instead\n",
    "# it would mix up the labels causing a confusion on what is what. \n",
    "\n",
    "# If we try to match the frequency after encoding we then fall into a problem since the frequency 1 is repeated twice\n",
    "# and so we won't be able to identify which is which.\n",
    "\n",
    "# Hence we use .where and set a unique value to each, then match and convert into an order from 0-12\n",
    "\n",
    "\n",
    "test_data = data.copy()\n",
    "\n",
    "test_data['Machine failure'] += np.where((test_data['TWF'] == 1) & (test_data['PWF'] == 1)  & (test_data['OSF'] == 1), 1, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['TWF'] == 1) & (test_data['OSF'] == 1), 4, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['HDF'] == 1) & (test_data['OSF'] == 1), 8, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['HDF'] == 1) & (test_data['PWF'] == 1), 12, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['TWF'] == 1) & (test_data['RNF'] == 1), 16, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['PWF'] == 1) & (test_data['OSF'] == 1), 20, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['PWF'] == 1), 24, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['TWF'] == 1), 30, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['OSF'] == 1), 36, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['RNF'] == 1), 42, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['HDF'] == 1), 48, 0)\n",
    "test_data['Machine failure'] += np.where((test_data['PWF'] == 0) & (test_data['TWF'] == 0) & (test_data['OSF'] == 0) &\n",
    "               (test_data['HDF'] == 0) & (test_data['Machine failure'] == 1), 52, 0)\n",
    "\n",
    "\n",
    "# Here the unique labels are converted to a proper order \n",
    "\n",
    "test_data.loc[test_data['Machine failure'] == 116, \"Machine failure\"] = 1 # TWFPWFOSF\n",
    "test_data.loc[test_data['Machine failure'] == 89, \"Machine failure\"] = 2 # TWFRNF\n",
    "test_data.loc[test_data['Machine failure'] == 71, \"Machine failure\"] = 3 # TWFOSF\n",
    "test_data.loc[test_data['Machine failure'] == 81, \"Machine failure\"] = 4 # PWFOSF\n",
    "test_data.loc[test_data['Machine failure'] == 85, \"Machine failure\"] = 5 # HDFPWF\n",
    "test_data.loc[test_data['Machine failure'] == 93, \"Machine failure\"] = 6 # HDFOSF\n",
    "test_data.loc[test_data['Machine failure'] == 31, \"Machine failure\"] = 7 # TWF\n",
    "test_data.loc[test_data['Machine failure'] == 42, \"Machine failure\"] = 8 # RNF\n",
    "test_data.loc[test_data['Machine failure'] == 25, \"Machine failure\"] = 9 # PWF\n",
    "test_data.loc[test_data['Machine failure'] == 37, \"Machine failure\"] = 10 # OSF\n",
    "test_data.loc[test_data['Machine failure'] == 49, \"Machine failure\"] = 11 # HDF\n",
    "test_data.loc[test_data['Machine failure'] == 53, \"Machine failure\"] = 12 # UF\n",
    "\n",
    "\n",
    "# 0 - No machine failure\n",
    "# 1 = TWFPWFOSF\n",
    "# 2 = TWFRNF\n",
    "# 3 = TWFOSF\n",
    "# 4 = PWFOSF\n",
    "# 5 = HDFPWF\n",
    "# 6 = HDFOSF\n",
    "# 7 = TWF\n",
    "# 8 = RNF - No machine failure but failure occurs\n",
    "# 9 = PWF\n",
    "# 10 = OSF\n",
    "# 11 = HDF\n",
    "# 12 = UF, Machine failure is equal to 1 but none of the failure types had occured \n",
    "# which is basically an undefined failure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove the failure columns since we have merged them with machine_failure\n",
    "test_data = test_data.drop(labels = ['TWF', 'HDF', 'PWF', 'OSF', 'RNF'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling the dataset to 10000 for each label\n",
    "sample = 10000\n",
    "test_data = test_data.groupby('Machine failure').apply(lambda x: x.sample(sample,replace=True))\n",
    "\n",
    "# Since we had use group by machine failure, the index is now machine failure so in X_train we will be able to\n",
    "# see the target label (Machine failure) so for that we need to change the index from group by machine failure\n",
    "# to the normal count index\n",
    "test_data = test_data.droplevel(0).reset_index()\n",
    "test_data = test_data.drop(labels = 'index', axis =1)\n",
    "\n",
    "\n",
    "# Setting the column'Type' with datatype object to int64 by encoding\n",
    "le =LabelEncoder()\n",
    "test_data['Type'] = le.fit_transform(test_data['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295.3\n",
      "304.5\n"
     ]
    }
   ],
   "source": [
    "# Implementing binning\n",
    "# Taking the Minimum and maximum and diving it into three sections of low, medium and high\n",
    "\n",
    "min_value = test_data['Air temperature [K]'].min()\n",
    "max_value = test_data['Air temperature [K]'].max()\n",
    "print(min_value)\n",
    "print(max_value)\n",
    "\n",
    "# Store in Bins \n",
    "bins = np.linspace(min_value, max_value, 4)\n",
    "bins\n",
    "\n",
    "# Create labels\n",
    "labels = ['low', 'medium', 'high']\n",
    "\n",
    "# Replace to the value in the bin based on the label\n",
    "test_data['Air temperature [K]'] = pd.cut(test_data['Air temperature [K]'], bins=bins, labels=labels, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305.8\n",
      "313.8\n"
     ]
    }
   ],
   "source": [
    "# Implementing binning\n",
    "# Taking the Minimum and maximum and diving it into three sections of low, medium and high\n",
    "\n",
    "min_value_2 = test_data['Process temperature [K]'].min()\n",
    "max_value_2 = test_data['Process temperature [K]'].max()\n",
    "print(min_value_2)\n",
    "print(max_value_2)\n",
    "\n",
    "# Store in Bins \n",
    "bins_2 = np.linspace(min_value_2, max_value_2, 4)\n",
    "bins_2\n",
    "\n",
    "# Create labels\n",
    "labels_2 = ['low', 'medium', 'high']\n",
    "\n",
    "# Replace to the value in the bin based on the label\n",
    "test_data['Process temperature [K]'] = pd.cut(test_data['Process temperature [K]'], bins=bins_2, labels=labels_2, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168\n",
      "2886\n"
     ]
    }
   ],
   "source": [
    "# Implementing binning\n",
    "# Taking the Minimum and maximum and diving it into three sections of low, medium and high\n",
    "\n",
    "\n",
    "min_value_3 = test_data['Rotational speed [rpm]'].min()\n",
    "max_value_3 = test_data['Rotational speed [rpm]'].max()\n",
    "print(min_value_3)\n",
    "print(max_value_3)\n",
    "\n",
    "# Store in Bins \n",
    "bins_3 = np.linspace(min_value_3, max_value_3, 4)\n",
    "bins_3\n",
    "\n",
    "# Create labels\n",
    "labels_3 = ['low', 'medium', 'high']\n",
    "\n",
    "# Replace to the value in the bin based on the label\n",
    "test_data['Rotational speed [rpm]'] = pd.cut(test_data['Rotational speed [rpm]'], bins=bins_3, labels=labels_3, include_lowest=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8\n",
      "76.6\n"
     ]
    }
   ],
   "source": [
    "# Implementing binning\n",
    "# Taking the Minimum and maximum and diving it into three sections of low, medium and high\n",
    "\n",
    "\n",
    "min_value_4 = test_data['Torque [Nm]'].min()\n",
    "max_value_4 = test_data['Torque [Nm]'].max()\n",
    "print(min_value_4)\n",
    "print(max_value_4)\n",
    "\n",
    "# Store in Bins \n",
    "bins_4 = np.linspace(min_value_4, max_value_4, 4)\n",
    "bins_4\n",
    "\n",
    "# Create labels\n",
    "labels_4 = ['low', 'medium', 'high']\n",
    "\n",
    "# Replace to the value in the bin based on the label\n",
    "test_data['Torque [Nm]'] = pd.cut(test_data['Torque [Nm]'], bins=bins_4, labels=labels_4, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "253\n"
     ]
    }
   ],
   "source": [
    "# Implementing binning\n",
    "# Taking the Minimum and maximum and diving it into three sections of low, medium and high\n",
    "\n",
    "min_value_5 = test_data['Tool wear [min]'].min()\n",
    "max_value_5 = test_data['Tool wear [min]'].max()\n",
    "print(min_value_5)\n",
    "print(max_value_5)\n",
    "\n",
    "# Store in Bins \n",
    "bins_5 = np.linspace(min_value_5, max_value_5, 4)\n",
    "bins_5\n",
    "\n",
    "# Create labels\n",
    "labels_5 = ['low', 'medium', 'high']\n",
    "\n",
    "# Replace to the value in the bin based on the label\n",
    "test_data['Tool wear [min]'] = pd.cut(test_data['Tool wear [min]'], bins=bins_5, labels=labels_5, include_lowest=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the features for getting a better result\n",
    "\n",
    "le =LabelEncoder()\n",
    "\n",
    "# test_data['Type'] = le.fit_transform(test_data['Type'])\n",
    "test_data['Air temperature [K]'] = le.fit_transform(test_data['Air temperature [K]'])\n",
    "test_data['Process temperature [K]'] = le.fit_transform(test_data['Process temperature [K]'])\n",
    "test_data['Rotational speed [rpm]'] = le.fit_transform(test_data['Rotational speed [rpm]'])\n",
    "test_data['Torque [Nm]'] = le.fit_transform(test_data['Torque [Nm]'])\n",
    "test_data['Tool wear [min]'] = le.fit_transform(test_data['Tool wear [min]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster sampling the dataset from 130000 to 13000 instances\n",
    "test_data = test_data.sample(frac=0.1, replace=True) # 13000 instances\n",
    "\n",
    "\n",
    "# Cluster sampling the dataset from 13000 to 8060 where 6045 is used for training and 2015 is used for testing\n",
    "test_data = test_data.sample(frac=0.62, replace=True) # 8060 instances\n",
    "\n",
    "\n",
    "\n",
    "# Defining X and y\n",
    "X = test_data.drop(labels = ['UDI', 'Product ID', 'Machine failure'], axis =1 )\n",
    "y = test_data['Machine failure']\n",
    "# X = test_data.iloc[:, 2:8]\n",
    "# y = test_data.iloc[:,8]\n",
    "\n",
    "\n",
    "\n",
    "# Splitting to training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 101)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# defining terms to be used for calculation\n",
    "n_rows = X_train.shape[0] # Instances in X_train\n",
    "class_list = y_train.unique() # Number of labels\n",
    "column_seq = X_train.columns # Column names\n",
    "df = X_train.copy() # storing X_train (features) in a dataframe for calculating\n",
    "column_list = df.columns # List of column names in df\n",
    "\n",
    "# add target column\n",
    "df[\"target\"] = y_train\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the probabilities\n",
    "feature_count = defaultdict(lambda: defaultdict(int)) # stores class- feature pair count\n",
    "class_count = defaultdict(int) # store frequency of class globally\n",
    "class_probability = defaultdict(int) # prior probability of class (class count / number of rows)\n",
    "alpha = 1\n",
    "\n",
    "if not df.empty:\n",
    "    \n",
    "    # for each row we will count the number of features\n",
    "    for row in df.values:\n",
    "        # storing the target class values\n",
    "        target_row = row[-1] \n",
    "        # going through each feature and add 1 to sum up to the number of features\n",
    "        for column in (row[:-1]):\n",
    "            feature_count[target_row][column] += 1 \n",
    "\n",
    "for target in y_train:\n",
    "    # storing the number of classes\n",
    "    target_class = len(class_count) \n",
    "    class_count[target] += 1\n",
    "\n",
    "# calculation class_count into probabilities\n",
    "for feature_class, count in class_count.items():\n",
    "    # converting counts to probabilities\n",
    "    class_probability[feature_class] = count / n_rows \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will take some time since we have 120,000 instances\n",
    "\n",
    "# hold predictions by our model\n",
    "y_pred = []\n",
    "\n",
    "data = X_test.copy()\n",
    "data['target'] = y_test\n",
    "\n",
    "# for each row in the dataset\n",
    "for row in data.values:\n",
    "    \n",
    "    # parse the target\n",
    "    target = row[-1]\n",
    "    \n",
    "    # query point\n",
    "    query = row[:-1]\n",
    "    \n",
    "    # get the log probability distribution\n",
    "    # pd = probability distribution\n",
    "    pd = predict(query, feature_count) #, class_feature_pair_mean, class_feature_pair_std)\n",
    "\n",
    "    # maximum a posteriori to get the class index\n",
    "    pred_class =np.argmax(list(pd.values()))\n",
    "\n",
    "    # get the class label\n",
    "    pred_label = list(feature_count.keys())[pred_class]\n",
    "    \n",
    "    # append the prediction to the list\n",
    "    y_pred.append(pred_label)\n",
    "\n",
    "y_pred = np.array(y_pred, dtype= int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Test labels:  [ 3 11  1  5  0 10 10  7  3  5]\n",
      "Predicted labels: [2 6 1 2 7 6 6 3 3 2]\n"
     ]
    }
   ],
   "source": [
    "# Printing out the test labels vs the predicted labels\n",
    "print(\"10 Test labels: \", y_test[:10].values)\n",
    "print(\"Predicted labels:\", y_pred[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the predicted labels we can match the label number to the below machine failure except \n",
    "# for No machine failure and RNF since the machine does not fail in these two cases\n",
    "\n",
    "# 0 - No machine failure\n",
    "# 1 = TWFPWFOSF\n",
    "# 2 = TWFRNF\n",
    "# 3 = TWFOSF\n",
    "# 4 = PWFOSF\n",
    "# 5 = HDFPWF\n",
    "# 6 = HDFOSF\n",
    "# 7 = TWF\n",
    "# 8 = RNF - No machine failure but failure occurs\n",
    "# 9 = PWF\n",
    "# 10 = OSF\n",
    "# 11 = HDF\n",
    "# 12 = UF, Machine failure is equal to 1 but none of the failure types had occured \n",
    "# which is basically an undefined failure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.337468982630273\n"
     ]
    }
   ],
   "source": [
    "# compute accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "# Printing accuracy\n",
    "# We notice that the accuracy is less and this is due to how the Naive bayes is created, since we are doing a \n",
    "# Probabilistic Naive Bayes we are getting a very low accuracy\n",
    "print(\"Test Accuracy: \",test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 40,   3,  14,   4,   0,   0,   2,   5,   0,  15,   6,   0,  56],\n",
       "       [  0, 182,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0, 176,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,  88,  79,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,  49,  25,   0,   0,  28,  12,   0,   0,  38,   0,   0],\n",
       "       [  0,   0,  51,   0,   0,   0,   0,  53,   0,   0,  71,   0,   0],\n",
       "       [  0,   0,   0,  81,   0,   0,  87,   0,   0,   0,   0,   0,   0],\n",
       "       [ 17,   4,  21,  24,   0,   0,   0,  23,   0,   6,   4,   0,  48],\n",
       "       [ 15,   0,  24,  11,   0,   0,  25,   0,   0,   0,   8,   0,  56],\n",
       "       [ 31,   3,  21,  22,   0,   0,   7,   4,   0,  25,   7,   0,  38],\n",
       "       [  0,   2,  63,  24,   0,   0,  37,   0,   0,   2,   6,   0,  19],\n",
       "       [ 13,   5,  24,  15,   0,   0,   8,  13,   0,   0,  16,   0,  26],\n",
       "       [ 26,  15,   0,   0,   0,   0,   0,  15,   0,  15,   0,   0,  62]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.28      0.28       145\n",
      "           1       0.85      1.00      0.92       182\n",
      "           2       0.33      1.00      0.50       176\n",
      "           3       0.28      0.47      0.35       167\n",
      "           4       0.00      0.00      0.00       152\n",
      "           5       0.00      0.00      0.00       175\n",
      "           6       0.45      0.52      0.48       168\n",
      "           7       0.18      0.16      0.17       147\n",
      "           8       0.00      0.00      0.00       139\n",
      "           9       0.40      0.16      0.23       158\n",
      "          10       0.04      0.04      0.04       153\n",
      "          11       0.00      0.00      0.00       120\n",
      "          12       0.20      0.47      0.28       133\n",
      "\n",
      "    accuracy                           0.34      2015\n",
      "   macro avg       0.23      0.31      0.25      2015\n",
      "weighted avg       0.25      0.34      0.27      2015\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# printing the classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# hold predictions by our model\n",
    "y_pred = []\n",
    "\n",
    "data = X_train.copy()\n",
    "data['target'] = y_train\n",
    "\n",
    "# for each row in the dataset\n",
    "for row in data.values:\n",
    "    \n",
    "    # parse the target\n",
    "    target = row[-1]\n",
    "    \n",
    "    # query point\n",
    "    query = row[:-1]\n",
    "    \n",
    "    # get the log probability distribution\n",
    "    # pd = probability distribution\n",
    "    pd = predict(query, feature_count) #, class_feature_pair_mean, class_feature_pair_std)\n",
    "\n",
    "    # maximum a posteriori to get the class index\n",
    "    pred_class =np.argmax(list(pd.values()))\n",
    "\n",
    "    # get the class label\n",
    "    pred_label = list(feature_count.keys())[pred_class]\n",
    "    \n",
    "    # append the prediction to the list\n",
    "    y_pred.append(pred_label)\n",
    "\n",
    "y_pred = np.array(y_pred, dtype= int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.3301902398676592\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Accuracy: \",accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
